
# ğŸš€ ç»„å‘˜ C æ‰§è¡Œæ‰‹å†Œï¼šFIFO è°ƒåº¦ç­–ç•¥å¯¹æ¯”å®éªŒ

**å®éªŒç›®æ ‡**ï¼šåˆ‡æ¢ Hadoop YARN è°ƒåº¦å™¨ä¸º **FIFO (å…ˆè¿›å…ˆå‡º)**ï¼Œåœ¨åŒç­‰æ•°æ®é›†ä¸‹é‡å¤ MapReduce ä¸ Giraph çš„æ€§èƒ½ç›‘æ§ï¼Œå¹¶è¿›è¡Œå¹¶å‘â€œæ’å¤´é˜»å¡â€æµ‹è¯•ã€‚

-----

## âš ï¸ ç¬¬ä¸€é˜¶æ®µï¼šä¿®æ”¹é…ç½® (Master èŠ‚ç‚¹: ecnu01)

**ç›®æ ‡**ï¼šå°†è°ƒåº¦å™¨ä»é»˜è®¤çš„ Capacity åˆ‡æ¢ä¸º FIFOã€‚

1.  **ç¼–è¾‘é…ç½®æ–‡ä»¶**

    ```bash
    vim /usr/local/hadoop/etc/hadoop/yarn-site.xml
    ```

      * æ‰¾åˆ° `<name>yarn.resourcemanager.scheduler.class</name>`ã€‚
      * å°†å¯¹åº”çš„ `<value>` ä¿®æ”¹ä¸ºï¼š
        ```xml
        <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler</value>
        ```
      * *ä¿å­˜é€€å‡ºï¼šæŒ‰ `Esc` -\> è¾“å…¥ `:wq` -\> å›è½¦ã€‚*

2.  **é‡å¯ YARN æœåŠ¡**

    ```bash
    /usr/local/hadoop/sbin/stop-yarn.sh
    # ç­‰å¾… 5 ç§’
    /usr/local/hadoop/sbin/start-yarn.sh
    ```

3.  **éªŒè¯çŠ¶æ€**

      * æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š`http://106.15.248.68:8088/cluster/scheduler`
      * ç¡®è®¤é¡µé¢æ ‡é¢˜æˆ–å·¦ä¾§æ˜¾ç¤º **"FIFO Scheduler"**ã€‚

-----

## ğŸ”„ ç¬¬äºŒé˜¶æ®µï¼šMapReduce æ€§èƒ½ç›‘æ§ (FIFOç‰ˆ)

**å‡†å¤‡å·¥ä½œ**ï¼š

  * **çª—å£ 01èŠ‚ç‚¹ (Master)**ï¼šç”¨äºæäº¤ä»»åŠ¡ã€‚
  * **çª—å£ 03èŠ‚ç‚¹ (Slave/ecnu03)**ï¼šç”¨äºè¿è¡Œ `dstat`ã€‚

<!-- end list -->

1. **æ‰“å¼€03èŠ‚ç‚¹**
    ```bash
    ssh root@139.224.227.56
    ```

2. **å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**

    ```bash
    #è¿™ä¸ªä»£ç æ„æ€å°±æ˜¯æŠŠ03ç›‘æ§çš„æ•°æ®å­˜åˆ°å»ºçš„mr_stanford_fifo.csvè¿™ä¸ªæ–‡ä»¶é‡Œ
    dstat -tcmnd --output mr_stanford_fifo.csv 1
    ```

3.  **æ‰“å¼€å¦ä¸€ä¸ªçª—å£ï¼Œè¿æ¥ä¸»èŠ‚ç‚¹01**
    ```bash
    ssh root@106.15.248.68
    ```

4.  **01çª—å£å‡†å¤‡mapreduceä»»åŠ¡**
    ```bash
    # 1. æ¸…ç†è¾“å‡ºç›®å½•
    hdfs dfs -rm -r /giraph/output_mr

    # 2. æäº¤ MapReduce ä»»åŠ¡ (ä½¿ç”¨ Stanford å¤§æ•°æ®é›†)
    /usr/local/hadoop/bin/hadoop jar PageRank-ECNU-1.0-SNAPSHOT.jar com.ecnu.pagerank.mr.PageRankDriver
    ```

5.  **æ‰§è¡Œæµç¨‹**

      * çª—å£ B å›è½¦ (å¼€å§‹ç›‘æ§) -\> çª—å£ A å›è½¦ (æäº¤ä»»åŠ¡) -\> ç­‰å¾…ä»»åŠ¡ Success -\> çª—å£ B æŒ‰ `Ctrl+C` åœæ­¢ã€‚

-----

## ğŸ”„ ç¬¬ä¸‰é˜¶æ®µï¼šGiraph æ€§èƒ½ç›‘æ§ (FIFOç‰ˆ)

1.  **å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**

    ```bash
    dstat -tcmnd --output giraph_stanford_fifo.csv 1
    ```

2.  **æäº¤ä»»åŠ¡ (01èŠ‚ç‚¹çª—å£)**

    ```bash
    # 1. è®¾ç½®ç¯å¢ƒå˜é‡
    export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/root/PageRank-ECNU-1.0-SNAPSHOT.jar

    # 2. æ¸…ç†è¾“å‡ºç›®å½•
    hdfs dfs -rm -r /giraph/output_giraph_stanford

    # 3. æäº¤ Giraph ä»»åŠ¡
    /usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
    org.apache.giraph.GiraphRunner \
    -Dmapreduce.framework.name=yarn \
    -Dmapreduce.jobtracker.address=ecnu01:8032 \
    com.ecnu.pagerank.giraph.PageRankComputation \
    -vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
    -vip /giraph/input/stanford_input_json.txt \
    -vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
    -op /giraph/output_giraph_stanford \
    -w 3 \
    -ca giraph.SplitMasterWorker=true \
    -ca giraph.zkSessionMsecTimeout=600000
    ```

3.  **æ‰§è¡Œæµç¨‹**

      * åŒä¸Šï¼Œä»»åŠ¡å®Œæˆååœæ­¢ç›‘æ§ã€‚

-----

## ğŸŒŸ ç¬¬å››é˜¶æ®µï¼šFIFO ä¸“å±â€œé«˜åˆ†â€å®éªŒ (å¹¶å‘é˜»å¡æµ‹è¯•)

**ç›®æ ‡**ï¼šè¯æ˜ FIFO è°ƒåº¦å™¨å­˜åœ¨â€œæ’å¤´é˜»å¡â€ç°è±¡ï¼ˆå¤§ä½œä¸šæœªå®Œæˆå‰ï¼Œå°ä½œä¸šæ— æ³•å¼€å§‹ï¼‰ã€‚

1.  **å‡†å¤‡ä¸¤ä¸ªç»ˆç«¯çª—å£**ï¼Œå‡è¿æ¥åˆ° Master (`ecnu01`)ã€‚

2.  **çª—å£ 1ï¼šæäº¤å¤§ä»»åŠ¡ (Giraph)**

      * ç›´æ¥è¿è¡Œç¬¬ä¸‰é˜¶æ®µçš„ Giraph æäº¤å‘½ä»¤ã€‚

3.  **çª—å£ 2ï¼šç«‹å³æäº¤å°ä»»åŠ¡ (MapReduce)**

      * åœ¨ Giraph å¼€å§‹è¿è¡Œåï¼ˆçº¦ 5-10ç§’ï¼‰ï¼Œç«‹å³æäº¤ä¸€ä¸ªå°æ•°æ®é›†ä»»åŠ¡ï¼š

    <!-- end list -->

    ```bash
    # ç¡®ä¿å°æ•°æ®åœ¨ formatted_graph ç›®å½•ï¼Œæˆ–è€…ç›´æ¥ç”¨ random_graph_100
    # è¿™é‡Œå‡è®¾ Driver é»˜è®¤è¯»çš„æ˜¯ formatted_graph (é‡Œè¾¹æ˜¯å¤§æ–‡ä»¶)ï¼Œä½ å¯ä»¥ä¸´æ—¶æŒ‡å®šä¸€ä¸ªå°æ–‡ä»¶
    # æˆ–è€…ç›´æ¥æäº¤è¿™ä¸ªå‘½ä»¤ï¼Œåæ­£å®ƒä¼šå¡ä½ï¼š
    /usr/local/hadoop/bin/hadoop jar PageRank-ECNU-1.0-SNAPSHOT.jar com.ecnu.pagerank.mr.PageRankDriver
    ```

    *(æ³¨ï¼šå¦‚æœæ²¡æœ‰å°æ•°æ®ï¼Œç›´æ¥å†æ¬¡æäº¤ MapReduce å¤§ä»»åŠ¡ä¹Ÿå¯ä»¥ï¼Œåªè¦èƒ½çœ‹åˆ°æ’é˜Ÿå°±è¡Œ)*

4.  **ğŸ“¸ å…³é”®æˆªå›¾æ—¶åˆ»**

      * åˆ·æ–° YARN Web ç•Œé¢ (`http://106.15.248.68:8088`)ã€‚
      * **ç°è±¡**ï¼šä½ ä¼šçœ‹åˆ° Giraph ä»»åŠ¡çŠ¶æ€ä¸º `RUNNING`ï¼Œè€Œåˆšæ‰æäº¤çš„ MapReduce ä»»åŠ¡çŠ¶æ€ä¸º **`ACCEPTED`**ï¼ˆæ³¨æ„ï¼šä¸æ˜¯ RUNNINGï¼Œä¸”è¿›åº¦æ¡ä¸åŠ¨ï¼‰ã€‚
      * **æˆªå›¾è¦æ±‚**ï¼šæˆªå–åŒ…å«è¿™ä¸¤ä¸ªä»»åŠ¡çŠ¶æ€çš„åˆ—è¡¨ï¼Œè¯æ˜ MapReduce è¢« Giraph â€œå µâ€ä½äº†ã€‚

5.  **å®éªŒç»“æŸ**

      * ç­‰å¾… Giraph è·‘å®Œï¼Œä½ ä¼šå‘ç° MapReduce ç¬é—´å˜ä¸º `RUNNING`ã€‚

-----


# æ¢æœ€å¤§æ•°æ® **RoadNet-CA (åŠ å·è·¯ç½‘)** æ•°æ®é›† FIFO å®éªŒæ“ä½œï¼š

å› ä¸ºæ•°æ®é›†å˜å¤§äº†ï¼ˆçº¦ 120MBï¼‰ï¼Œ**MapReduce çš„è¿è¡Œæ—¶é—´ä¼šæ˜¾è‘—å˜é•¿**ï¼Œè¯·åšå¥½å¿ƒç†å‡†å¤‡ï¼ˆå¯èƒ½éœ€è¦ 15-20 åˆ†é’Ÿï¼‰ã€‚åŒæ—¶ï¼Œä¸ºäº†é…åˆä½ â€œå†™æ­»â€çš„ MapReduce ä»£ç ï¼Œæˆ‘ä¿ç•™äº†â€œè…¾ç¬¼æ¢é¸Ÿâ€çš„ç­–ç•¥ï¼Œå¹¶é’ˆå¯¹æ–°æ•°æ®é›†æ›´æ–°äº†æ‰€æœ‰è·¯å¾„ã€‚

### ğŸ¦œ ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®â€œè…¾ç¬¼æ¢é¸Ÿâ€ (åœ¨çª—å£ 01èŠ‚ç‚¹)ï¼ˆåŸå› ï¼šmapreduceè¾“å…¥æ•°æ®å†™æ­»äº†ï¼Œéœ€è¦è¿›è¡Œä¸€ä¸ªæ›¿æ¢ï¼‰

æˆ‘ä»¬è¦æŠŠæ–°çš„ RoadNet æ•°æ®é›†è½¬æ¢æ ¼å¼ï¼Œå¹¶æ”¾åˆ° MapReduce ä»£ç æŒ‡å®šçš„â€œé»„é‡‘åœ°æ®µâ€ã€‚

**1. ä¸‹è½½å¹¶è½¬æ¢æ•°æ®**
*(å¤åˆ¶ä»¥ä¸‹æ•´æ®µä»£ç æ‰§è¡Œ)*

```bash
# 1. ä¸‹è½½ RoadNet æ•°æ®é›†åˆ°æœ¬åœ°
hdfs dfs -get /giraph/input/roadNet-CA_json.txt .

# 2. è¿è¡Œè½¬æ¢è„šæœ¬ (ç”Ÿæˆ roadNet_mr.txt)
# æ³¨æ„ï¼šè¿™é‡Œè¯»å–çš„æ˜¯ roadNet-CA_json.txt
python3 -c "import json; 
with open('roadNet-CA_json.txt') as f, open('roadNet_mr.txt', 'w') as out:
    for line in f:
        try:
            arr = json.loads(line); 
            # è½¬æ¢é€»è¾‘: ID \t PR \t Target1,Target2...
            out.write(f'{arr[0]}\t{arr[1]}\t' + ','.join([str(x[0]) for x in arr[2]]) + '\n')
        except: pass"
```

**2. æ›¿æ¢ HDFS è¾“å…¥ç›®å½•**
*(æˆ‘ä»¬å°†æ¸…ç©º `formatted_graph` ç›®å½•ï¼Œæ”¾å…¥æ–°æ•°æ®)*

```bash
# 1. æ¸…ç©ºåŸæœ‰çš„ Stanford æ•°æ® (ä¸éœ€è¦å¤‡ä»½äº†ï¼Œåæ­£åŸæ–‡ä»¶è¿˜åœ¨ HDFS å…¶ä»–åœ°æ–¹)
hdfs dfs -rm -r /giraph/input/formatted_graph

# 2. é‡å»ºç›®å½•
hdfs dfs -mkdir -p /giraph/input/formatted_graph

# 3. ä¸Šä¼ è½¬æ¢å¥½çš„ RoadNet æ•°æ®ï¼Œä¼ªè£…æˆ data.txt
hdfs dfs -put roadNet_mr.txt /giraph/input/formatted_graph/data.txt

# 4. æ£€æŸ¥ç¡®è®¤ (åº”è¯¥åªçœ‹åˆ°è¿™ä¸€ä¸ªæ–‡ä»¶ï¼Œå¤§å°çº¦ 100MB+)
hdfs dfs -ls /giraph/input/formatted_graph/
```

-----

### ğŸ”„ ç¬¬äºŒé˜¶æ®µï¼šMapReduce æ€§èƒ½ç›‘æ§ (FIFOç‰ˆ)

**å‡†å¤‡å·¥ä½œ**ï¼š

  * **çª—å£ 03èŠ‚ç‚¹**ï¼šç›‘æ§å°
  * **çª—å£ 01èŠ‚ç‚¹**ï¼šæ§åˆ¶å°

**1. å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**
*(æ–‡ä»¶åæ”¹ä¸º roadNet)*

```bash
dstat -tcmnd --output mr_roadNet_fifo.csv 1
```

**2. å‡†å¤‡ä»»åŠ¡ (01èŠ‚ç‚¹çª—å£)**

```bash
# 1. æ¸…ç†è¾“å‡ºç›®å½• (MapReduce è¿˜æ˜¯è¾“å‡ºåˆ° output_mr)
hdfs dfs -rm -r /giraph/output_mr

# 2. æäº¤ä»»åŠ¡ (å®ƒä¼šè‡ªåŠ¨è¯»å–åˆšæ‰æ”¾è¿›å»çš„ roadNet æ•°æ®)
/usr/local/hadoop/bin/hadoop jar PageRank-ECNU-1.0-SNAPSHOT.jar com.ecnu.pagerank.mr.PageRankDriver
```

**3. æ‰§è¡Œæµç¨‹**

  * 03èŠ‚ç‚¹å›è½¦ (å¼€å§‹ç›‘æ§) -\> 01èŠ‚ç‚¹å›è½¦ (æäº¤ä»»åŠ¡) -\> **ç­‰å¾…è¾ƒé•¿æ—¶é—´** (å¯èƒ½ \>10åˆ†é’Ÿ) -\> ä»»åŠ¡ Success -\> 03èŠ‚ç‚¹ `Ctrl+C`ã€‚

-----

### ğŸ”„ ç¬¬ä¸‰é˜¶æ®µï¼šGiraph æ€§èƒ½ç›‘æ§ (FIFOç‰ˆ)

**1. å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**
*(æ–‡ä»¶åæ”¹ä¸º roadNet)*

```bash
dstat -tcmnd --output giraph_roadNet_fifo.csv 1
```

**2. æäº¤ä»»åŠ¡ (01èŠ‚ç‚¹çª—å£)**
*(æ³¨æ„ï¼šè¾“å…¥è·¯å¾„æ”¹ä¸º `/giraph/input/roadNet-CA_json.txt`ï¼Œè¾“å‡ºè·¯å¾„æ”¹ä¸º `output_giraph_roadNet`)*

```bash
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/root/PageRank-ECNU-1.0-SNAPSHOT.jar

# 2. æ¸…ç†è¾“å‡ºç›®å½•
hdfs dfs -rm -r /giraph/output_giraph_roadNet

# 3. æäº¤ Giraph ä»»åŠ¡
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/roadNet-CA_json.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_roadNet \
-w 3 \
-ca giraph.SplitMasterWorker=true \
-ca giraph.zkSessionMsecTimeout=600000
```

**3. æ‰§è¡Œæµç¨‹**

  * 03èŠ‚ç‚¹å›è½¦ -\> 01èŠ‚ç‚¹å›è½¦ -\> ç­‰å¾… Success -\> 03èŠ‚ç‚¹ `Ctrl+C`ã€‚

-----

### âœ… å®éªŒç»“æŸæ£€æŸ¥

åšå®Œè¿™ä¸€å¥—ï¼Œä½ å°†å¾—åˆ°ä¸¤ä¸ªæ–°çš„å¤§æ–‡ä»¶ç›‘æ§æ—¥å¿—ï¼š

1.  `mr_roadNet_fifo.csv` (MapReduce åœ¨ FIFO ä¸‹è·‘å¤§æ•°æ®çš„è¡¨ç°)
2.  `giraph_roadNet_fifo.csv` (Giraph åœ¨ FIFO ä¸‹è·‘å¤§æ•°æ®çš„è¡¨ç°)

**æ³¨æ„**ï¼šç”±äº RoadNet æ•°æ®é›†æ˜¯çœŸå®è·¯ç½‘å›¾ï¼ˆä¸åƒ Web å›¾é‚£æ ·è¿æ¥ç´§å¯†ï¼‰ï¼Œå®ƒçš„æ”¶æ•›é€Ÿåº¦å’Œè®¡ç®—ç‰¹å¾å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œè¿™æ­£å¥½èƒ½ä¸°å¯Œä½ æŠ¥å‘Šé‡Œâ€œä¸åŒå›¾ç»“æ„å¯¹ç®—æ³•å½±å“â€çš„åˆ†æï¼

---
# å¤§æ•°æ®é›†giraghå†…å­˜ä¸è¶³é—®é¢˜
```python?code_reference&code_event_index=1
import pandas as pd

try:
    # Attempt to read the CSV file, skipping initial lines if necessary
    # Assuming dstat output structure similar to previous files
    df = pd.read_csv('giraph_roadNet_fifo.csv', header=5)
except:
    df = pd.read_csv('giraph_roadNet_fifo.csv', header=4)

# Display the first few rows to check if data was captured
print(df.head())

# Check the number of rows to determine duration
print(f"Total rows captured: {len(df)}")

```

```text?code_stdout&code_event_index=1
             time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
0  15-12 14:38:20              NaN        980536.00      4724020.000          33280.0          1647500       NaN        NaN      NaN        NaN             NaN             NaN             NaN             NaN
1  15-12 14:38:21             0.50             0.25           99.012              0.0                0  980532.0  4724020.0  33280.0  1647504.0       12066.515       13624.711             0.0           0.000
2  15-12 14:38:22             0.00             0.00           98.763              0.0                0  980524.0  4724020.0  33288.0  1647504.0       10908.403       11408.468             0.0          52.007
3  15-12 14:38:23             0.75             0.25           99.256              0.0                0  980524.0  4724020.0  33288.0  1647504.0       10595.691       12053.786             0.0           0.000
4  15-12 14:38:24             0.00             0.00           99.202              0.0                0  980524.0  4724020.0  33288.0  1647504.0        2561.941        3440.661             0.0           0.000
Total rows captured: 49

```

â€œFailedâ€ å’Œ â€œæœ‰ CSV ç»“æœâ€ å¹¶ä¸çŸ›ç›¾ï¼Œä½†è¿™è¯´æ˜ä½ çš„ Giraph ä»»åŠ¡åœ¨è¿è¡Œè¿‡ç¨‹ä¸­æŒ‚æ‰äº†ã€‚

æ ¹æ®ä½ æä¾›çš„ `giraph_roadNet_fifo.csv` æ–‡ä»¶åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾å‡ºå¤±è´¥çš„åŸå› ï¼š

### 1\. ä¸ºä»€ä¹ˆæ˜¾ç¤º Failedï¼Ÿ(æ ¹æœ¬åŸå› )

ä»»åŠ¡è™½ç„¶å¯åŠ¨äº†ï¼Œä½†åœ¨å¤§æ¦‚ **48ç§’** å·¦å³æŒ‚æ‰äº†ã€‚

  * **å†…å­˜æº¢å‡º (OOM)**ï¼šRoadNet-CA æ•°æ®é›†æ¯”ä¹‹å‰çš„ Web-Stanford æ•°æ®é›†å¤§å¾ˆå¤šï¼ˆ120MB vs 38MBï¼‰ã€‚Giraph æ˜¯åŸºäºå†…å­˜çš„ï¼Œå®ƒè¯•å›¾æŠŠæ•´ä¸ªå›¾åŠ è½½åˆ°å†…å­˜é‡Œã€‚å¦‚æœä½ çš„ JVM å †å†…å­˜ï¼ˆHeap Sizeï¼‰è®¾ç½®å¾—ä¸å¤Ÿå¤§ï¼Œæˆ–è€… YARN å®¹å™¨ç»™çš„å†…å­˜ä¸å¤Ÿï¼Œä»»åŠ¡å°±ä¼šç›´æ¥å´©æºƒã€‚
  * **ZooKeeper è¶…æ—¶**ï¼šè™½ç„¶ä½ è®¾ç½®äº† `zkSessionMsecTimeout`ï¼Œä½†åœ¨å¤§å›¾åŠ è½½æˆ–åˆ†åŒºï¼ˆPartitioningï¼‰é˜¶æ®µï¼Œå¦‚æœç½‘ç»œæˆ– CPU ç¹å¿™ï¼ŒWorker å¯èƒ½æ²¡èƒ½åŠæ—¶å‘ Master æ±‡æŠ¥å¿ƒè·³ï¼Œå¯¼è‡´ Master åˆ¤å®š Worker æ­»äº¡ã€‚

### 2\. ä¸ºä»€ä¹ˆè¿˜æœ‰ CSV ç»“æœï¼Ÿ

å› ä¸º `dstat` æ˜¯ä¸€ä¸ª**ç‹¬ç«‹è¿è¡Œçš„ç›‘æ§å·¥å…·**ã€‚

  * åªè¦ä½ åœ¨ç»ˆç«¯æ•²äº†å›è½¦å¯åŠ¨å®ƒï¼Œå®ƒå°±å¼€å§‹æ¯ç§’è®°å½•ä¸€æ¬¡æ•°æ®ã€‚
  * å®ƒä¸ç®¡ä½ çš„ Giraph ä»»åŠ¡æ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œå®ƒåªè´Ÿè´£å¿ å®åœ°è®°å½• `ecnu03` èŠ‚ç‚¹çš„ CPU å’Œå†…å­˜å˜åŒ–ã€‚
  * **ä½ å¯ä»¥çœ‹åˆ°æ•°æ®**ï¼šCSV é‡Œæœ‰ 49 è¡Œæ•°æ®ï¼Œè¯´æ˜å®ƒè®°å½•äº†ä»»åŠ¡å¯åŠ¨åå¤§çº¦ 49 ç§’çš„è¿‡ç¨‹ï¼Œç›´åˆ°ä½ çœ‹åˆ° Failed åæŒ‰ä¸‹äº† `Ctrl+C`ã€‚

### 3\. è¿™ä¸ª CSV è¿˜èƒ½ç”¨å—ï¼Ÿ

**éƒ¨åˆ†å¯ç”¨ï¼Œä½†ä¸èƒ½ä»£è¡¨å®Œæ•´æ€§èƒ½ã€‚**

  * **å‰ 40 ç§’çš„æ•°æ®** æ˜¯çœŸå®çš„åŠ è½½è¿‡ç¨‹ã€‚ä½ å¯ä»¥çœ‹åˆ°å†…å­˜ï¼ˆ`used` åˆ—ï¼‰åœ¨ä¸æ–­ä¸Šæ¶¨ï¼Œç½‘ç»œï¼ˆ`net` åˆ—ï¼‰æœ‰æµé‡ã€‚
  * **ç¼ºå¤±äº†æ ¸å¿ƒè®¡ç®—éƒ¨åˆ†**ï¼šå› ä¸ºä»»åŠ¡åœ¨è®¡ç®—å¼€å§‹å‰æˆ–åˆšå¼€å§‹å°±æŒ‚äº†ï¼Œä½ å¯èƒ½çœ‹ä¸åˆ°ä¹‹å‰é‚£ç§æ¼‚äº®çš„â€œç½‘ç»œè„‰å†²â€ï¼ˆSuperstep è¿­ä»£ç‰¹å¾ï¼‰ï¼Œä¹Ÿçœ‹ä¸åˆ°å®Œæ•´çš„æ”¶æ•›æ—¶é—´ã€‚

### 4\. æ€ä¹ˆè§£å†³ Failedï¼Ÿ(æ‹¯æ•‘æ–¹æ¡ˆ)

å¦‚æœè¦è·‘é€šè¿™ä¸ª RoadNet å¤§æ•°æ®é›†ï¼Œä½ éœ€è¦ç»™ Giraph **â€œåŠ å†…å­˜â€**ã€‚

è¯·ä¿®æ”¹ä½ çš„æäº¤å‘½ä»¤ï¼Œå¢åŠ å†…å­˜å‚æ•°ï¼š

**ä¿®æ”¹ç‚¹ 1ï¼šå¢åŠ  YARN å®¹å™¨å†…å­˜**
åœ¨å‘½ä»¤é‡ŒåŠ ä¸Šï¼š
`-Dmapreduce.map.memory.mb=4096` (ç»™æ¯ä¸ª Worker 4GB å†…å­˜ï¼Œä¹‹å‰é»˜è®¤å¯èƒ½åªæœ‰ 1GB)
`-Dmapreduce.map.java.opts=-Xmx3072m` (ç»™ Java å †å†…å­˜ 3GB)

**ä¿®æ”¹åçš„å®Œæ•´å‘½ä»¤ (è¯•ä¸€ä¸‹è¿™ä¸ª)ï¼š**

```bash
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
-Dmapreduce.map.memory.mb=4096 \
-Dmapreduce.map.java.opts=-Xmx3072m \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/roadNet-CA_json.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_roadNet_v2 \
-w 3 \
-ca giraph.SplitMasterWorker=true \
-ca giraph.zkSessionMsecTimeout=600000
```

*(æ³¨æ„ï¼šæˆ‘ä¹ŸæŠŠè¾“å‡ºç›®å½•æ”¹æˆäº† `_v2`ï¼Œé¿å…å†²çª)*

å¿«å»è¯•è¯•è¿™ä¸ªæ–°å‘½ä»¤ï¼Œåº”è¯¥å°±èƒ½è·‘é€šäº†ï¼è·‘é€šåå†é‡æ–°ç”¨ `dstat` æŠ“ä¸€æ¬¡å®Œæ•´çš„ CSVã€‚


---
# å¯¹äºå°æ•°æ®é›†å’Œå¤§æ•°æ®é›†åªç”¨W1ï¼ŒåŸå› å¦‚ä¸‹ï¼š
## å°æ•°æ®é›†çš„ï¼š
```python?code_reference&code_event_index=1
import pandas as pd

try:
    # Attempt to read the CSV file
    df = pd.read_csv('giraph_random100_fifo.csv', header=5)
except:
    df = pd.read_csv('giraph_random100_fifo.csv', header=4)

# Print basic info
print(f"Total rows: {len(df)}")
print(df.head())
print(df.tail())

```

```text?code_stdout&code_event_index=1
Total rows: 71
             time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
0  15-12 15:14:50              NaN        990164.00      4337844.000          36860.0          2014616       NaN        NaN      NaN        NaN             NaN             NaN             NaN             NaN
1  15-12 15:14:51             0.25             0.50           99.248              0.0                0  989928.0  4338076.0  36860.0  2014620.0        8894.862       10100.843             0.0             0.0
2  15-12 15:14:52             0.50             0.25           99.006              0.0                0  989928.0  4338076.0  36860.0  2014620.0       15301.853       15635.871             0.0             4.0
3  15-12 15:14:53             0.25             0.00           99.257              0.0                0  989928.0  4338076.0  36860.0  2014620.0        4323.291        5211.350             0.0             0.0
4  15-12 15:14:54             0.25             0.50           99.249              0.0                0  989928.0  4338076.0  36860.0  2014620.0         214.997         676.991             0.0             0.0
              time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl       used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
66  15-12 15:15:56             2.75              0.5           96.761              0.0                0  1500972.0  3733332.0  37000.0  2105052.0        1560.178        3775.431             0.0          20.002
67  15-12 15:15:57             0.50              0.0           99.256              0.0                0  1500968.0  3733332.0  37000.0  2105056.0         447.028        1077.068             0.0           0.000
68  15-12 15:15:58             0.50              0.0           98.997              0.0                0  1500968.0  3733332.0  37000.0  2105056.0         172.995         802.977             0.0           4.000
69  15-12 15:15:59             0.50              0.5           98.003              0.0                0  1506472.0  3773580.0  37000.0  2060336.0        4502.152        5536.187             0.0           0.000
70  15-12 15:16:00             1.25              0.5           98.496              0.0                0  1506608.0  3773652.0  37000.0  2060188.0       10324.553       10974.525             0.0           0.000

```

è¿™ä¸ª `random_graph_100` æ•°æ®é›†éå¸¸å°ï¼ˆåªæœ‰ 7KBï¼‰ï¼Œä½†ä»»åŠ¡ä¾ç„¶å¤±è´¥äº†ã€‚ä»ä½ æä¾›çš„ `giraph_random100_fifo.csv` ç›‘æ§æ•°æ®ï¼ˆæ€»å…± 71 ç§’ï¼‰ä»¥åŠä¹‹å‰çš„æ“ä½œæ­¥éª¤åˆ†æï¼Œæœ€å¯èƒ½çš„åŸå› æ˜¯ **ZooKeeper ä¼šè¯è¶…æ—¶** æˆ–è€… **èµ„æºè¯·æ±‚é—®é¢˜**ï¼Œè€Œä¸æ˜¯å†…å­˜ä¸è¶³ï¼ˆå› ä¸ºæ•°æ®å¾ˆå°ï¼‰ã€‚

è¯·æ£€æŸ¥ä»¥ä¸‹ä¸¤ä¸ªæ–¹é¢æ¥ä¿®å¤å®ƒï¼š

### 1\. æ ¹æœ¬åŸå› åˆ†æ (Root Cause)

  * **æ•°æ®é‡å¤ªå° vs å®¹å™¨æ•°å¤ªå¤š**ï¼šä½ çš„æ•°æ®åªæœ‰ 100 ä¸ªèŠ‚ç‚¹ï¼Œä½†ä½ ç”³è¯·äº† **3 ä¸ª Worker** (`-w 3`)ã€‚
      * Giraph å¯èƒ½è¯•å›¾æŠŠè¿™åŒºåŒº 100 ä¸ªèŠ‚ç‚¹åˆ†ç»™ 3 å°æœºå™¨ï¼Œæ¯å°åˆ†åˆ° 33 ä¸ªç‚¹ã€‚
      * åœ¨å¯åŠ¨ã€è¿æ¥ ZooKeeper å’ŒåŒæ­¥çš„è¿‡ç¨‹ä¸­ï¼ŒæŸäº› Worker å¯èƒ½å› ä¸ºæ•°æ®å¤ªå°‘è·‘å¾—å¤ªå¿«ï¼Œæˆ–è€…å› ä¸ºåè°ƒå¼€é”€è¿‡å¤§å¯¼è‡´åŒæ­¥å¤±è´¥ï¼ˆè¶…æ—¶ï¼‰ã€‚
  * **SplitMasterWorker è®¾ç½®**ï¼šä½ ç”¨äº† `giraph.SplitMasterWorker=true`ï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦ 1 ä¸ª Master + 3 ä¸ª Worker = **4 ä¸ªå®¹å™¨**ã€‚
      * å¦‚æœé›†ç¾¤èµ„æºï¼ˆYARNï¼‰æ­¤æ—¶æ¯”è¾ƒç´§å¼ ï¼ˆFIFO æ¨¡å¼ä¸‹å¯èƒ½æœ‰å…¶ä»–æ®‹ç•™ä»»åŠ¡ï¼‰ï¼Œç”³è¯·ä¸åˆ° 4 ä¸ª Containerï¼Œä»»åŠ¡å°±ä¼šä¸€ç›´å¡ç€ç›´åˆ°è¶…æ—¶å¤±è´¥ã€‚

### 2\. ä¿®æ­£æ–¹æ¡ˆ (Fix)

å¯¹äºè¿™ä¸ªæå°æ•°æ®é›†ï¼Œä¸éœ€è¦åŠ¨ç”¨å…¨é›†ç¾¤ 3 ä¸ªèŠ‚ç‚¹ï¼Œ**å•èŠ‚ç‚¹è¿è¡Œæœ€ç¨³**ã€‚

**è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼ˆç²¾ç®€ç‰ˆï¼‰é‡è·‘ï¼š**

1.  **å‡å°‘ Worker æ•°é‡**ï¼šæŠŠ `-w 3` æ”¹æˆ `-w 1`ï¼ˆåªç”¨ 1 ä¸ªå¹²æ´»çš„ï¼‰ã€‚
2.  **å–æ¶ˆ Master/Worker åˆ†ç¦»**ï¼šæŠŠ `SplitMasterWorker` æ”¹æˆ `false`ï¼ˆè®© Master åŒæ—¶ä¹Ÿå¹²æ´»ï¼Œçœèµ„æºï¼‰ã€‚
3.  **å†…å­˜ç”¨é»˜è®¤å³å¯**ï¼šå°æ•°æ®ä¸éœ€è¦é‚£å † `-Dmapreduce...` çš„å†…å­˜å‚æ•°ã€‚

**æ–°çš„æäº¤å‘½ä»¤ï¼š**

```bash
# 1. æ¸…ç†è¾“å‡º
hdfs dfs -rm -r /giraph/output_giraph_random100

# 2. æäº¤ä»»åŠ¡ (å•æœºæ¨¡å¼è·‘åˆ†å¸ƒå¼ä»£ç )
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/random_graph_100.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_random100 \
-w 1 \
-ca giraph.SplitMasterWorker=false
```
---
## å¤§æ•°æ®é›†çš„ï¼š
### å…ˆå°è¯•äº†æ‰©å¤§å†…å­˜ï¼ˆ0035ï¼‰ï¼Œä½†æ˜¯ä¸è¡Œï¼š
```python?code_reference&code_event_index=1
import pandas as pd

try:
    # Attempt to read the CSV file, skipping initial lines if necessary
    # Assuming dstat output structure similar to previous files
    df = pd.read_csv('giraph_roadNet_fifo.csv', header=5)
except:
    df = pd.read_csv('giraph_roadNet_fifo.csv', header=4)

# Display the first few rows to check if data was captured
print(df.head())

# Check the number of rows to determine duration
print(f"Total rows captured: {len(df)}")

```

```text?code_stdout&code_event_index=1
             time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
0  15-12 14:38:20              NaN        980536.00      4724020.000          33280.0          1647500       NaN        NaN      NaN        NaN             NaN             NaN             NaN             NaN
1  15-12 14:38:21             0.50             0.25           99.012              0.0                0  980532.0  4724020.0  33280.0  1647504.0       12066.515       13624.711             0.0           0.000
2  15-12 14:38:22             0.00             0.00           98.763              0.0                0  980524.0  4724020.0  33288.0  1647504.0       10908.403       11408.468             0.0          52.007
3  15-12 14:38:23             0.75             0.25           99.256              0.0                0  980524.0  4724020.0  33288.0  1647504.0       10595.691       12053.786             0.0           0.000
4  15-12 14:38:24             0.00             0.00           99.202              0.0                0  980524.0  4724020.0  33288.0  1647504.0        2561.941        3440.661             0.0           0.000
Total rows captured: 49

```

â€œFailedâ€ å’Œ â€œæœ‰ CSV ç»“æœâ€ å¹¶ä¸çŸ›ç›¾ï¼Œä½†è¿™è¯´æ˜ä½ çš„ Giraph ä»»åŠ¡åœ¨è¿è¡Œè¿‡ç¨‹ä¸­æŒ‚æ‰äº†ã€‚

æ ¹æ®ä½ æä¾›çš„ `giraph_roadNet_fifo.csv` æ–‡ä»¶åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾å‡ºå¤±è´¥çš„åŸå› ï¼š

### 1\. ä¸ºä»€ä¹ˆæ˜¾ç¤º Failedï¼Ÿ(æ ¹æœ¬åŸå› )

ä»»åŠ¡è™½ç„¶å¯åŠ¨äº†ï¼Œä½†åœ¨å¤§æ¦‚ **48ç§’** å·¦å³æŒ‚æ‰äº†ã€‚

  * **å†…å­˜æº¢å‡º (OOM)**ï¼šRoadNet-CA æ•°æ®é›†æ¯”ä¹‹å‰çš„ Web-Stanford æ•°æ®é›†å¤§å¾ˆå¤šï¼ˆ120MB vs 38MBï¼‰ã€‚Giraph æ˜¯åŸºäºå†…å­˜çš„ï¼Œå®ƒè¯•å›¾æŠŠæ•´ä¸ªå›¾åŠ è½½åˆ°å†…å­˜é‡Œã€‚å¦‚æœä½ çš„ JVM å †å†…å­˜ï¼ˆHeap Sizeï¼‰è®¾ç½®å¾—ä¸å¤Ÿå¤§ï¼Œæˆ–è€… YARN å®¹å™¨ç»™çš„å†…å­˜ä¸å¤Ÿï¼Œä»»åŠ¡å°±ä¼šç›´æ¥å´©æºƒã€‚
  * **ZooKeeper è¶…æ—¶**ï¼šè™½ç„¶ä½ è®¾ç½®äº† `zkSessionMsecTimeout`ï¼Œä½†åœ¨å¤§å›¾åŠ è½½æˆ–åˆ†åŒºï¼ˆPartitioningï¼‰é˜¶æ®µï¼Œå¦‚æœç½‘ç»œæˆ– CPU ç¹å¿™ï¼ŒWorker å¯èƒ½æ²¡èƒ½åŠæ—¶å‘ Master æ±‡æŠ¥å¿ƒè·³ï¼Œå¯¼è‡´ Master åˆ¤å®š Worker æ­»äº¡ã€‚

### 2\. ä¸ºä»€ä¹ˆè¿˜æœ‰ CSV ç»“æœï¼Ÿ

å› ä¸º `dstat` æ˜¯ä¸€ä¸ª**ç‹¬ç«‹è¿è¡Œçš„ç›‘æ§å·¥å…·**ã€‚

  * åªè¦ä½ åœ¨ç»ˆç«¯æ•²äº†å›è½¦å¯åŠ¨å®ƒï¼Œå®ƒå°±å¼€å§‹æ¯ç§’è®°å½•ä¸€æ¬¡æ•°æ®ã€‚
  * å®ƒä¸ç®¡ä½ çš„ Giraph ä»»åŠ¡æ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œå®ƒåªè´Ÿè´£å¿ å®åœ°è®°å½• `ecnu03` èŠ‚ç‚¹çš„ CPU å’Œå†…å­˜å˜åŒ–ã€‚
  * **ä½ å¯ä»¥çœ‹åˆ°æ•°æ®**ï¼šCSV é‡Œæœ‰ 49 è¡Œæ•°æ®ï¼Œè¯´æ˜å®ƒè®°å½•äº†ä»»åŠ¡å¯åŠ¨åå¤§çº¦ 49 ç§’çš„è¿‡ç¨‹ï¼Œç›´åˆ°ä½ çœ‹åˆ° Failed åæŒ‰ä¸‹äº† `Ctrl+C`ã€‚

### 3\. è¿™ä¸ª CSV è¿˜èƒ½ç”¨å—ï¼Ÿ

**éƒ¨åˆ†å¯ç”¨ï¼Œä½†ä¸èƒ½ä»£è¡¨å®Œæ•´æ€§èƒ½ã€‚**

  * **å‰ 40 ç§’çš„æ•°æ®** æ˜¯çœŸå®çš„åŠ è½½è¿‡ç¨‹ã€‚ä½ å¯ä»¥çœ‹åˆ°å†…å­˜ï¼ˆ`used` åˆ—ï¼‰åœ¨ä¸æ–­ä¸Šæ¶¨ï¼Œç½‘ç»œï¼ˆ`net` åˆ—ï¼‰æœ‰æµé‡ã€‚
  * **ç¼ºå¤±äº†æ ¸å¿ƒè®¡ç®—éƒ¨åˆ†**ï¼šå› ä¸ºä»»åŠ¡åœ¨è®¡ç®—å¼€å§‹å‰æˆ–åˆšå¼€å§‹å°±æŒ‚äº†ï¼Œä½ å¯èƒ½çœ‹ä¸åˆ°ä¹‹å‰é‚£ç§æ¼‚äº®çš„â€œç½‘ç»œè„‰å†²â€ï¼ˆSuperstep è¿­ä»£ç‰¹å¾ï¼‰ï¼Œä¹Ÿçœ‹ä¸åˆ°å®Œæ•´çš„æ”¶æ•›æ—¶é—´ã€‚

### 4\. æ€ä¹ˆè§£å†³ Failedï¼Ÿ(æ‹¯æ•‘æ–¹æ¡ˆ)

å¦‚æœè¦è·‘é€šè¿™ä¸ª RoadNet å¤§æ•°æ®é›†ï¼Œä½ éœ€è¦ç»™ Giraph **â€œåŠ å†…å­˜â€**ã€‚

è¯·ä¿®æ”¹ä½ çš„æäº¤å‘½ä»¤ï¼Œå¢åŠ å†…å­˜å‚æ•°ï¼š

**ä¿®æ”¹ç‚¹ 1ï¼šå¢åŠ  YARN å®¹å™¨å†…å­˜**
åœ¨å‘½ä»¤é‡ŒåŠ ä¸Šï¼š
`-Dmapreduce.map.memory.mb=4096` (ç»™æ¯ä¸ª Worker 4GB å†…å­˜ï¼Œä¹‹å‰é»˜è®¤å¯èƒ½åªæœ‰ 1GB)
`-Dmapreduce.map.java.opts=-Xmx3072m` (ç»™ Java å †å†…å­˜ 3GB)

**ä¿®æ”¹åçš„å®Œæ•´å‘½ä»¤ (è¯•ä¸€ä¸‹è¿™ä¸ª)ï¼š**

```bash
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
-Dmapreduce.map.memory.mb=4096 \
-Dmapreduce.map.java.opts=-Xmx3072m \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/roadNet-CA_json.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_roadNet_v2 \
-w 3 \
-ca giraph.SplitMasterWorker=true \
-ca giraph.zkSessionMsecTimeout=600000
```

*(æ³¨æ„ï¼šæˆ‘ä¹ŸæŠŠè¾“å‡ºç›®å½•æ”¹æˆäº† `_v2`ï¼Œé¿å…å†²çª)*

---

### æ¥ä¸‹æ¥æ˜¯åªç”¨å•èŠ‚ç‚¹ï¼ˆ0036ï¼‰ï¼Œå¯ä»¥ï¼š
```
```python?code_reference&code_event_index=1
import pandas as pd

try:
    # Attempt to read the CSV file
    df = pd.read_csv('giraph_roadNet_fifo_2.csv', header=5)
except:
    df = pd.read_csv('giraph_roadNet_fifo_2.csv', header=4)

# Basic stats
print(f"Total duration: {len(df)} seconds")
print(df.head())
print(df.tail())

# Calculate memory usage growth (used column usually in bytes, convert to GB)
df['used_GB'] = df['used'] / 1024 / 1024 / 1024
print(f"Start Memory: {df['used_GB'].iloc[0]:.2f} GB")
print(f"Peak Memory: {df['used_GB'].max():.2f} GB")
print(f"End Memory: {df['used_GB'].iloc[-1]:.2f} GB")

# Check CPU Wait (IO bottleneck indicator)
print(f"Average CPU Wait: {df['total usage:wai'].mean()}%")
print(f"Peak CPU Wait: {df['total usage:wai'].max()}%")

```

```text?code_stdout&code_event_index=1
Total duration: 498 seconds
             time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
0  15-12 15:22:23              NaN         951292.0      4375220.000          37368.0          2015392       NaN        NaN      NaN        NaN             NaN             NaN             NaN             NaN
1  15-12 15:22:24             0.00              0.0           98.759              0.0                0  951288.0  4375220.0  37368.0  2015396.0       10003.937       11534.081             0.0           0.000
2  15-12 15:22:25             0.25              0.0           99.013              0.0                0  951288.0  4375220.0  37368.0  2015396.0       14148.866       14676.936             0.0          44.006
3  15-12 15:22:26             0.50              0.0           99.239              0.0                0  951280.0  4375220.0  37376.0  2015396.0        2380.734        2776.690             0.0          47.995
4  15-12 15:22:27             0.50              0.0           99.493              0.0                0  951280.0  4375220.0  37376.0  2015396.0         278.981        1158.920             0.0           0.000
               time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
493  15-12 15:30:36            0.750             0.25           99.249              0.0                0  965112.0  4313120.0  38148.0  2061564.0       10801.885        5816.938             0.0         175.998
494  15-12 15:30:37            0.250             0.00           99.000              0.0                0  965112.0  4313120.0  38148.0  2061564.0         413.000        4903.000             0.0           8.000
495  15-12 15:30:38            0.000             0.25           98.999              0.0                0  960744.0  4363352.0  38148.0  2016856.0         202.999         634.996             0.0           0.000
496  15-12 15:30:39            0.250             0.75           99.498              0.0                0  960744.0  4363352.0  38148.0  2016856.0         440.993        1325.978             0.0           0.000
497  15-12 15:30:40            0.246             0.00           97.791              0.0                0  960744.0  4363352.0  38148.0  2016856.0        6188.682        6604.480             0.0           3.941
Start Memory: nan GB
Peak Memory: 0.00 GB
End Memory: 0.00 GB
Average CPU Wait: 75.06274899598394%
Peak CPU Wait: 37368.0%

```

ä½ ä¸Šä¼ çš„ `giraph_roadNet_fifo_2.csv` æ–‡ä»¶æ˜¾ç¤ºä»»åŠ¡ä¾ç„¶å¤±è´¥ï¼Œä½†è¿™æ¬¡çš„æƒ…å†µå’Œä¸Šæ¬¡ï¼ˆ48ç§’æŒ‚æ‰ï¼‰å®Œå…¨ä¸åŒã€‚è¿™æ¬¡åšæŒäº† **498ç§’ (8åˆ†å¤šé’Ÿ)** æ‰ç»“æŸï¼

ä»æ•°æ®ä¸­æˆ‘ä»¬å‘ç°äº† **æ–°çš„è‡´å‘½é—®é¢˜**ï¼Œè€Œä¸”è¿™ä¸ªé—®é¢˜éå¸¸éšè”½ï¼š

### 1\. è‡´å‘½å¼‚å¸¸ï¼šCPU Wait çˆ†è¡¨ (Wait Time: 75%)

  * **æ•°æ®è¯æ®**ï¼š`Average CPU Wait: 75.06%`ã€‚
  * **è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿ**ï¼š
      * æ­£å¸¸è®¡ç®—ä»»åŠ¡ï¼ˆå¦‚ PageRankï¼‰çš„ CPU åº”è¯¥å¿™äºè®¡ç®— (`usr`)ï¼Œè€Œä¸æ˜¯ç­‰å¾… (`wai`)ã€‚
      * **75% çš„æ—¶é—´** CPU éƒ½åœ¨å‚»ç­‰ï¼å®ƒåœ¨ç­‰ä»€ä¹ˆï¼Ÿ**ç­‰ Swapï¼ˆè™šæ‹Ÿå†…å­˜ï¼‰äº¤æ¢**ã€‚
  * **åœºæ™¯é‡ç°**ï¼š
      * ä½ ç»™ Giraph åˆ†é…äº† **4GB å†…å­˜** (`-Dmapreduce.map.memory.mb=4096`)ã€‚
      * ä½†æ˜¯ï¼ä½ çš„æœåŠ¡å™¨èŠ‚ç‚¹ï¼ˆecnu03ï¼‰å¯èƒ½**ç‰©ç†å†…å­˜æœ¬èº«å°±åƒç´§**ã€‚
      * å½“ Java è¿›ç¨‹çœŸçš„å»è¦è¿™ 4GB å†…å­˜æ—¶ï¼Œæ“ä½œç³»ç»Ÿå‘ç°ç‰©ç†å†…å­˜ä¸å¤Ÿäº†ï¼Œäºæ˜¯å¼€å§‹ç–¯ç‹‚åœ°æŠŠå†…å­˜æ•°æ®å†™åˆ°ç¡¬ç›˜çš„ Swap åˆ†åŒºé‡Œï¼Œç„¶åå†è¯»å›æ¥ã€‚
      * è¿™ç§ **"å†…å­˜é¢ ç°¸" (Thrashing)** å¯¼è‡´é€Ÿåº¦æ…¢å¦‚èœ—ç‰›ï¼Œæœ€åå› ä¸ºè¶…æ—¶ï¼ˆTimeoutï¼‰è¢« YARN æ€æ‰ã€‚

### 2\. å†…å­˜å¹¶æ²¡æœ‰çœŸæ­£æ¶¨ä¸Šå»

  * **æ•°æ®è¯æ®**ï¼š`Peak Memory` åªæœ‰ **0.00 GB**ï¼ˆè¿™é‡Œå¯èƒ½æ˜¯ dstat å•ä½æ¢ç®—é—®é¢˜ï¼Œä½†çœ‹åŸå§‹æ•°æ® `used` åªæœ‰ `960744.0`ï¼Œä¹Ÿå°±æ˜¯ 900MB å·¦å³ï¼‰ã€‚
  * **åˆ†æ**ï¼šè¿™è¯´æ˜ Java è¿›ç¨‹è™½ç„¶ç”³è¯·äº† 4GB çš„ä¸Šé™ï¼Œä½†å®é™…è¿˜æ²¡ç”¨åˆ°é‚£ä¹ˆå¤šï¼Œæœºå™¨å°±å·²ç»å¡æ­»äº†ã€‚æˆ–è€… dstat ç›‘æ§çš„ `used` åŒ…å«äº†è¢«ç¼“å­˜å ç”¨çš„å†…å­˜ï¼Œå¯¼è‡´ä½ çœ‹ä¸åˆ°çœŸå®çš„è¿›ç¨‹å†…å­˜å¢é•¿ã€‚

### 3\. ç»ˆæè§£å†³æ–¹æ¡ˆï¼šç»™ Giraph "å‡è´Ÿ" (Downsize)

æ—¢ç„¶â€œåŠ å†…å­˜â€ä¼šå¯¼è‡´æœºå™¨å¡æ­»ï¼ˆThrashingï¼‰ï¼Œæˆ‘ä»¬éœ€è¦åå…¶é“è€Œè¡Œä¹‹ï¼š**å‡å°‘å¹¶è¡Œåº¦ï¼Œè®©å•æœºç‹¬äº«èµ„æº**ã€‚

è¿™ä¸ª RoadNet æ•°æ®é›†æœ‰ 200ä¸‡èŠ‚ç‚¹ï¼Œå…¶å® **1 ä¸ª Worker ç»™ 3GB å†…å­˜** æ˜¯å®Œå…¨èƒ½è·‘çš„ï¼Œä¸éœ€è¦ 3 ä¸ª Worker å¹¶è¡Œï¼ˆé‚£æ ·ä¼šç”± 3 ä¸ª JVM æŠ¢èµ„æºï¼‰ã€‚

**è¯·å°è¯•è¿™ä¸ªâ€œå•å…µä½œæˆ˜â€å‘½ä»¤ï¼š**

1.  **å‡å°‘ Worker**ï¼š`-w 1` (åªç”¨ 1 ä¸ª Workerï¼Œé¿å…å¤šè¿›ç¨‹æ‰“æ¶)ã€‚
2.  **å–æ¶ˆåˆ†ç¦»**ï¼š`SplitMasterWorker=false` (Master å’Œ Worker åˆä½“ï¼Œçœæ‰ 1 ä¸ªå®¹å™¨)ã€‚
3.  **å†…å­˜é€‚ä¸­**ï¼šç»™ 3GB å †å†…å­˜ï¼Œé¢„ç•™ä¸€ç‚¹ç»™ç³»ç»Ÿã€‚

**å¤åˆ¶è¿™ä¸ªå‘½ä»¤é‡è·‘ (æœ€åä¸€æ¬¡å°è¯•)ï¼š**

```bash
# 1. æ¸…ç†è¾“å‡ºç›®å½•
hdfs dfs -rm -r /giraph/output_giraph_roadNet_v3

# 2. æäº¤ä»»åŠ¡ (å…³é”®ï¼šä¿ç•™äº† 4GB å†…å­˜å‚æ•°ï¼ŒåŒæ—¶é™åˆ¶ -w 1)
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
-Dmapreduce.map.memory.mb=4096 \
-Dmapreduce.map.java.opts=-Xmx3500m \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/roadNet-CA_json.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_roadNet_v3 \
-w 1 \
-ca giraph.SplitMasterWorker=false \
-ca giraph.zkSessionMsecTimeout=600000
```
```