
# FIFO è°ƒåº¦ç­–ç•¥å¯¹æ¯”å®éªŒ

**å®éªŒç›®æ ‡**ï¼šåˆ‡æ¢ Hadoop YARN è°ƒåº¦å™¨ä¸º **FIFO (å…ˆè¿›å…ˆå‡º)**ï¼Œåœ¨åŒç­‰æ•°æ®é›†ä¸‹é‡å¤ MapReduce ä¸ Giraph çš„æ€§èƒ½ç›‘æ§ï¼Œå¹¶è¿›è¡Œå¹¶å‘â€œæ’å¤´é˜»å¡â€æµ‹è¯•ã€‚

-----
## uiç•Œé¢å¼€å¯history
æ£€æŸ¥HadoopæœåŠ¡çŠ¶æ€
```bash
# 01èŠ‚ç‚¹æŸ¥çœ‹æ˜¯å¦å¼€å¯ï¼Œçœ‹ç»“æœæ˜¯å¦æœ‰JobHistoryServer
jps
```
```bash
# å¯åŠ¨å†å²æœåŠ¡å™¨
mr-jobhistory-daemon.sh start historyserver
```
---

## ç¬¬ä¸€é˜¶æ®µï¼šä¿®æ”¹é…ç½® (Master èŠ‚ç‚¹: ecnu01)

**ç›®æ ‡**ï¼šå°†è°ƒåº¦å™¨ä»é»˜è®¤çš„ Capacity åˆ‡æ¢ä¸º FIFOã€‚

1.  **ç¼–è¾‘é…ç½®æ–‡ä»¶**

    ```bash
    nano /usr/local/hadoop/etc/hadoop/yarn-site.xml
    ```

      * æ‰¾åˆ° `<name>yarn.resourcemanager.scheduler.class</name>`ã€‚
      * å°†å¯¹åº”çš„ `<value>` ä¿®æ”¹ä¸ºï¼š
        ```xml
        <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler</value>
        ```
      * æ”¹å®ŒåæŒ‰ Ctrl+O ä¿å­˜ï¼ŒEnter ç¡®è®¤ï¼ŒCtrl+X é€€å‡º
      * ps:ä¸‰ç§è°ƒåº¦æˆ‘å·²ç»åœ¨xmlä¸­å¤‡æ³¨å¥½äº†
    
```bash 
    # å‘ç»™ ecnu02
    scp /usr/local/hadoop/etc/hadoop/yarn-site.xml root@ecnu02:/usr/local/hadoop/etc/hadoop/
    # å‘ç»™ ecnu03
    scp /usr/local/hadoop/etc/hadoop/yarn-site.xml root@ecnu03:/usr/local/hadoop/etc/hadoop/
    # å‘ç»™ ecnu04
    scp /usr/local/hadoop/etc/hadoop/yarn-site.xml root@ecnu04:/usr/local/hadoop/etc/hadoop/
```
2.  **é‡å¯ YARN æœåŠ¡**

    ```bash
    /usr/local/hadoop/sbin/stop-yarn.sh
    # ç­‰å¾… 5 ç§’
    /usr/local/hadoop/sbin/start-yarn.sh
    ```

3.  **éªŒè¯çŠ¶æ€**

      * æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š`http://106.15.248.68:8088/cluster/scheduler`
      * ç¡®è®¤é¡µé¢æ ‡é¢˜æˆ–å·¦ä¾§æ˜¾ç¤º **"FIFO Scheduler"**ã€‚

-----

## ç¬¬äºŒé˜¶æ®µï¼šMapReduce æ€§èƒ½ç›‘æ§ (FIFOç‰ˆ)

**å‡†å¤‡å·¥ä½œ**ï¼š

  * **çª—å£ 01èŠ‚ç‚¹ (Master)**ï¼šç”¨äºæäº¤ä»»åŠ¡ã€‚
  * **çª—å£ 03èŠ‚ç‚¹ (Slave/ecnu03)**ï¼šç”¨äºè¿è¡Œ `dstat`ã€‚

<!-- end list -->

1. **æ‰“å¼€03èŠ‚ç‚¹**
    ```bash
    ssh root@139.224.227.56
    ```

2. **å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**

    ```bash
    #è¿™ä¸ªä»£ç æ„æ€å°±æ˜¯æŠŠ03ç›‘æ§çš„æ•°æ®å­˜åˆ°å»ºçš„mr_stanford_fifo.csvè¿™ä¸ªæ–‡ä»¶é‡Œ
    dstat -tcmnd --output mr_stanford_fifo.csv 1
    ```

3.  **æ‰“å¼€å¦ä¸€ä¸ªçª—å£ï¼Œè¿æ¥ä¸»èŠ‚ç‚¹01**
    ```bash
    ssh root@106.15.248.68
    ```

4.  **01çª—å£å‡†å¤‡mapreduceä»»åŠ¡**
    ```bash
    # 1. å½»åº•æ¸…ç†æ—§æ•°æ®ï¼ˆå¥½ä¹ æƒ¯ï¼‰
    hdfs dfs -rm -r /giraph/output_mr

    # 2. è¿è¡Œä»»åŠ¡
    /usr/local/hadoop/bin/hadoop jar PageRank-ECNU-1.0-SNAPSHOT.jar \
    com.ecnu.pagerank.mr.PageRankDriver \
    -Dmapreduce.job.reduces=3 \
    -Dmapreduce.map.memory.mb=3072 \
    -Dmapreduce.map.java.opts=-Xmx2560m \
    -Dmapreduce.reduce.memory.mb=3072 \
    -Dmapreduce.reduce.java.opts=-Xmx2560m \
    -Dmapreduce.task.io.sort.mb=512 \
    /giraph/input/formatted_graph/stanford_mr.txt \
    /giraph/output_mr/iter_
    ```

5.  **æ‰§è¡Œæµç¨‹**

      * çª—å£ B å›è½¦ (å¼€å§‹ç›‘æ§) -\> çª—å£ A å›è½¦ (æäº¤ä»»åŠ¡) -\> ç­‰å¾…ä»»åŠ¡ Success -\> çª—å£ B æŒ‰ `Ctrl+C` åœæ­¢ã€‚

-----

## ç¬¬ä¸‰é˜¶æ®µï¼šGiraph æ€§èƒ½ç›‘æ§ (FIFOç‰ˆ)

1.  **å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**

    ```bash
    dstat -tcmnd --output giraph_stanford_fifo.csv 1
    ```

2.  **æäº¤ä»»åŠ¡ (01èŠ‚ç‚¹çª—å£)**

    ```bash
    # 1. è®¾ç½®ç¯å¢ƒå˜é‡
    export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/root/PageRank-ECNU-1.0-SNAPSHOT.jar

    # 2. æ¸…ç†è¾“å‡ºç›®å½•
    hdfs dfs -rm -r /giraph/output_giraph_stanford

    # 3. æäº¤ Giraph ä»»åŠ¡
    /usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
    org.apache.giraph.GiraphRunner \
    -Dmapreduce.framework.name=yarn \
    -Dmapreduce.jobtracker.address=ecnu01:8032 \
    com.ecnu.pagerank.giraph.PageRankComputation \
    -vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
    -vip /giraph/input/stanford_input_json.txt \
    -vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
    -op /giraph/output_giraph_stanford \
    -w 3 \
    -ca giraph.SplitMasterWorker=true \
    -ca giraph.zkSessionMsecTimeout=600000
    ```

3.  **æ‰§è¡Œæµç¨‹**

      * åŒä¸Šï¼Œä»»åŠ¡å®Œæˆååœæ­¢ç›‘æ§ã€‚

-----

## ç¬¬å››é˜¶æ®µ æ¢å¤§æ•°æ®é›†RoadNetå’Œå°æ•°æ®é›†random100  é‡å¤ç¬¬äºŒå’Œä¸‰é˜¶æ®µçš„å®éªŒ 

### ğŸ“£ä¸‹é¢ä»¥å¤§æ•°æ®é›†ä¸ºä¾‹å­ï¼š
### 1ï¼šè·‘MapReduce ï¼ˆåŒä¸­ç­‰æ•°æ®é›†ï¼‰

**å‡†å¤‡å·¥ä½œ**ï¼š
  * **çª—å£ 03èŠ‚ç‚¹**ï¼šç›‘æ§å°
  * **çª—å£ 01èŠ‚ç‚¹**ï¼šæ§åˆ¶å°

**1ï¸âƒ£. å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**

```bash
dstat -tcmnd --output mr_roadNet_fifo.csv 1
```

**2ï¸âƒ£. å‡†å¤‡ä»»åŠ¡ (01èŠ‚ç‚¹çª—å£)**
ï¼ˆæ³¨æ„ä¿®æ”¹inputè·¯å¾„ä¸ºäº†/input/formatted_graph/roadNet_mr.txt \ï¼‰
```bash
    # 1. å½»åº•æ¸…ç†æ—§æ•°æ®ï¼ˆå¥½ä¹ æƒ¯ï¼‰
    hdfs dfs -rm -r /giraph/output_mr

    # 2. è¿è¡Œä»»åŠ¡
    /usr/local/hadoop/bin/hadoop jar PageRank-ECNU-1.0-SNAPSHOT.jar \
    com.ecnu.pagerank.mr.PageRankDriver \
    -Dmapreduce.job.reduces=3 \
    -Dmapreduce.map.memory.mb=3072 \
    -Dmapreduce.map.java.opts=-Xmx2560m \
    -Dmapreduce.reduce.memory.mb=3072 \
    -Dmapreduce.reduce.java.opts=-Xmx2560m \
    -Dmapreduce.task.io.sort.mb=512 \
    /giraph/input/formatted_graph/roadNet_mr.txt \
    /giraph/output_mr/iter_
```
**3ï¸âƒ£. æ‰§è¡Œæµç¨‹**

  * 03èŠ‚ç‚¹å›è½¦ (å¼€å§‹ç›‘æ§) -\> 01èŠ‚ç‚¹å›è½¦ (æäº¤ä»»åŠ¡) -\> **ç­‰å¾…è¾ƒé•¿æ—¶é—´** (å¯èƒ½ \>10åˆ†é’Ÿ) -\> ä»»åŠ¡ Success -\> 03èŠ‚ç‚¹ `Ctrl+C`ã€‚

-----

### 2ï¼šè·‘Giraph ï¼ˆåŒä¸­ç­‰æ•°æ®é›†ï¼‰

**1ï¸âƒ£. å¯åŠ¨ç›‘æ§ (03èŠ‚ç‚¹çª—å£)**

```bash
dstat -tcmnd --output giraph_roadNet_fifo.csv 1
```

**2ï¸âƒ£. æäº¤ä»»åŠ¡ (01èŠ‚ç‚¹çª—å£)**
*(æ³¨æ„ï¼šè¾“å…¥è·¯å¾„æ”¹ä¸º `/giraph/input/roadNet-CA_json.txt`ï¼Œè¾“å‡ºè·¯å¾„æ”¹ä¸º `output_giraph_roadNet`)*

```bash
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/root/PageRank-ECNU-1.0-SNAPSHOT.jar

# 2. æ¸…ç†è¾“å‡ºç›®å½•
hdfs dfs -rm -r /giraph/output_giraph_roadNet

# 3. æäº¤ Giraph ä»»åŠ¡
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/roadNet-CA_json.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_roadNet \
-w 3 \
-ca giraph.SplitMasterWorker=true \
-ca giraph.zkSessionMsecTimeout=600000
```

**3ï¸âƒ£. æ‰§è¡Œæµç¨‹**

  * 03èŠ‚ç‚¹å›è½¦ -\> 01èŠ‚ç‚¹å›è½¦ -\> ç­‰å¾… Success -\> 03èŠ‚ç‚¹ `Ctrl+C`ã€‚

-----

### âœ… å®éªŒç»“æŸæ£€æŸ¥

åšå®Œè¿™ä¸€å¥—ï¼Œä½ å°†å¾—åˆ°ä¸¤ä¸ªæ–°çš„å¤§æ–‡ä»¶ç›‘æ§æ—¥å¿—ï¼š

1.  `mr_roadNet_fifo.csv` (03èŠ‚ç‚¹è¾“å…¥å‘½ä»¤ ls æŸ¥çœ‹æ˜¯å¦æœ‰è¿™ä¸ªæ–‡ä»¶)
2.  `giraph_roadNet_fifo.csv` (03èŠ‚ç‚¹è¾“å…¥å‘½ä»¤ ls æŸ¥çœ‹æ˜¯å¦æœ‰è¿™ä¸ªæ–‡ä»¶)

**æ³¨æ„**ï¼šç”±äº RoadNet æ•°æ®é›†æ˜¯çœŸå®è·¯ç½‘å›¾ï¼ˆä¸åƒ Web å›¾é‚£æ ·è¿æ¥ç´§å¯†ï¼‰ï¼Œå®ƒçš„æ”¶æ•›é€Ÿåº¦å’Œè®¡ç®—ç‰¹å¾å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œè¿™æ­£å¥½èƒ½ä¸°å¯Œä½ æŠ¥å‘Šé‡Œâ€œä¸åŒå›¾ç»“æ„å¯¹ç®—æ³•å½±å“â€çš„åˆ†æï¼

---
### å¤§æ•°æ®é›†ä¼šé‡åˆ°çš„é—®é¢˜â€”â€”giraghå†…å­˜ä¸è¶³é—®é¢˜
```python?code_reference&code_event_index=1
import pandas as pd

try:
    # Attempt to read the CSV file, skipping initial lines if necessary
    # Assuming dstat output structure similar to previous files
    df = pd.read_csv('giraph_roadNet_fifo.csv', header=5)
except:
    df = pd.read_csv('giraph_roadNet_fifo.csv', header=4)

# Display the first few rows to check if data was captured
print(df.head())

# Check the number of rows to determine duration
print(f"Total rows captured: {len(df)}")

```

```text?code_stdout&code_event_index=1
             time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
0  15-12 14:38:20              NaN        980536.00      4724020.000          33280.0          1647500       NaN        NaN      NaN        NaN             NaN             NaN             NaN             NaN
1  15-12 14:38:21             0.50             0.25           99.012              0.0                0  980532.0  4724020.0  33280.0  1647504.0       12066.515       13624.711             0.0           0.000
2  15-12 14:38:22             0.00             0.00           98.763              0.0                0  980524.0  4724020.0  33288.0  1647504.0       10908.403       11408.468             0.0          52.007
3  15-12 14:38:23             0.75             0.25           99.256              0.0                0  980524.0  4724020.0  33288.0  1647504.0       10595.691       12053.786             0.0           0.000
4  15-12 14:38:24             0.00             0.00           99.202              0.0                0  980524.0  4724020.0  33288.0  1647504.0        2561.941        3440.661             0.0           0.000
Total rows captured: 49

```

â€œFailedâ€ å’Œ â€œæœ‰ CSV ç»“æœâ€ å¹¶ä¸çŸ›ç›¾ï¼Œä½†è¿™è¯´æ˜ä½ çš„ Giraph ä»»åŠ¡åœ¨è¿è¡Œè¿‡ç¨‹ä¸­æŒ‚æ‰äº†ã€‚

æ ¹æ®ä½ æä¾›çš„ `giraph_roadNet_fifo.csv` æ–‡ä»¶åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾å‡ºå¤±è´¥çš„åŸå› ï¼š

####  1\. ä¸ºä»€ä¹ˆæ˜¾ç¤º Failedï¼Ÿ(æ ¹æœ¬åŸå› )

ä»»åŠ¡è™½ç„¶å¯åŠ¨äº†ï¼Œä½†åœ¨å¤§æ¦‚ **48ç§’** å·¦å³æŒ‚æ‰äº†ã€‚

  * **å†…å­˜æº¢å‡º (OOM)**ï¼šRoadNet-CA æ•°æ®é›†æ¯”ä¹‹å‰çš„ Web-Stanford æ•°æ®é›†å¤§å¾ˆå¤šï¼ˆ120MB vs 38MBï¼‰ã€‚Giraph æ˜¯åŸºäºå†…å­˜çš„ï¼Œå®ƒè¯•å›¾æŠŠæ•´ä¸ªå›¾åŠ è½½åˆ°å†…å­˜é‡Œã€‚å¦‚æœä½ çš„ JVM å †å†…å­˜ï¼ˆHeap Sizeï¼‰è®¾ç½®å¾—ä¸å¤Ÿå¤§ï¼Œæˆ–è€… YARN å®¹å™¨ç»™çš„å†…å­˜ä¸å¤Ÿï¼Œä»»åŠ¡å°±ä¼šç›´æ¥å´©æºƒã€‚
  * **ZooKeeper è¶…æ—¶**ï¼šè™½ç„¶ä½ è®¾ç½®äº† `zkSessionMsecTimeout`ï¼Œä½†åœ¨å¤§å›¾åŠ è½½æˆ–åˆ†åŒºï¼ˆPartitioningï¼‰é˜¶æ®µï¼Œå¦‚æœç½‘ç»œæˆ– CPU ç¹å¿™ï¼ŒWorker å¯èƒ½æ²¡èƒ½åŠæ—¶å‘ Master æ±‡æŠ¥å¿ƒè·³ï¼Œå¯¼è‡´ Master åˆ¤å®š Worker æ­»äº¡ã€‚

#### 2\. ä¸ºä»€ä¹ˆè¿˜æœ‰ CSV ç»“æœï¼Ÿ

å› ä¸º `dstat` æ˜¯ä¸€ä¸ª**ç‹¬ç«‹è¿è¡Œçš„ç›‘æ§å·¥å…·**ã€‚

  * åªè¦ä½ åœ¨ç»ˆç«¯æ•²äº†å›è½¦å¯åŠ¨å®ƒï¼Œå®ƒå°±å¼€å§‹æ¯ç§’è®°å½•ä¸€æ¬¡æ•°æ®ã€‚
  * å®ƒä¸ç®¡ä½ çš„ Giraph ä»»åŠ¡æ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œå®ƒåªè´Ÿè´£å¿ å®åœ°è®°å½• `ecnu03` èŠ‚ç‚¹çš„ CPU å’Œå†…å­˜å˜åŒ–ã€‚
  * **ä½ å¯ä»¥çœ‹åˆ°æ•°æ®**ï¼šCSV é‡Œæœ‰ 49 è¡Œæ•°æ®ï¼Œè¯´æ˜å®ƒè®°å½•äº†ä»»åŠ¡å¯åŠ¨åå¤§çº¦ 49 ç§’çš„è¿‡ç¨‹ï¼Œç›´åˆ°ä½ çœ‹åˆ° Failed åæŒ‰ä¸‹äº† `Ctrl+C`ã€‚

#### 3\. è¿™ä¸ª CSV è¿˜èƒ½ç”¨å—ï¼Ÿ

**éƒ¨åˆ†å¯ç”¨ï¼Œä½†ä¸èƒ½ä»£è¡¨å®Œæ•´æ€§èƒ½ã€‚**

  * **å‰ 40 ç§’çš„æ•°æ®** æ˜¯çœŸå®çš„åŠ è½½è¿‡ç¨‹ã€‚ä½ å¯ä»¥çœ‹åˆ°å†…å­˜ï¼ˆ`used` åˆ—ï¼‰åœ¨ä¸æ–­ä¸Šæ¶¨ï¼Œç½‘ç»œï¼ˆ`net` åˆ—ï¼‰æœ‰æµé‡ã€‚
  * **ç¼ºå¤±äº†æ ¸å¿ƒè®¡ç®—éƒ¨åˆ†**ï¼šå› ä¸ºä»»åŠ¡åœ¨è®¡ç®—å¼€å§‹å‰æˆ–åˆšå¼€å§‹å°±æŒ‚äº†ï¼Œä½ å¯èƒ½çœ‹ä¸åˆ°ä¹‹å‰é‚£ç§æ¼‚äº®çš„â€œç½‘ç»œè„‰å†²â€ï¼ˆSuperstep è¿­ä»£ç‰¹å¾ï¼‰ï¼Œä¹Ÿçœ‹ä¸åˆ°å®Œæ•´çš„æ”¶æ•›æ—¶é—´ã€‚

#### 4\. æ€ä¹ˆè§£å†³ Failedï¼Ÿï¼ˆåé¢éªŒè¯äº†è¿™ä¸ªè§£å†³æ–¹æ³•è¿˜æ˜¯ä¸è¡Œï¼Œè¦å¢å¤§å†…å­˜åŸºç¡€ä¸Šè¿˜è¦æŠŠw3æ”¹æˆw1ï¼‰

å¦‚æœè¦è·‘é€šè¿™ä¸ª RoadNet å¤§æ•°æ®é›†ï¼Œä½ éœ€è¦ç»™ Giraph **â€œåŠ å†…å­˜â€**ã€‚

è¯·ä¿®æ”¹ä½ çš„æäº¤å‘½ä»¤ï¼Œå¢åŠ å†…å­˜å‚æ•°ï¼š

**ä¿®æ”¹ç‚¹ 1ï¼šå¢åŠ  YARN å®¹å™¨å†…å­˜**
åœ¨å‘½ä»¤é‡ŒåŠ ä¸Šï¼š
`-Dmapreduce.map.memory.mb=4096` (ç»™æ¯ä¸ª Worker 4GB å†…å­˜ï¼Œä¹‹å‰é»˜è®¤å¯èƒ½åªæœ‰ 1GB)
`-Dmapreduce.map.java.opts=-Xmx3072m` (ç»™ Java å †å†…å­˜ 3GB)

**ä¿®æ”¹åçš„å®Œæ•´å‘½ä»¤ (è¯•ä¸€ä¸‹è¿™ä¸ª)ï¼š**

```bash
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
-Dmapreduce.map.memory.mb=4096 \
-Dmapreduce.map.java.opts=-Xmx3072m \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/roadNet-CA_json.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_roadNet_v2 \
-w 3 \
-ca giraph.SplitMasterWorker=true \
-ca giraph.zkSessionMsecTimeout=600000
```

*(æ³¨æ„ï¼šæˆ‘ä¹ŸæŠŠè¾“å‡ºç›®å½•æ”¹æˆäº† `_v2`ï¼Œé¿å…å†²çª)*

---
## å¯¹äºå°æ•°æ®é›†å’Œå¤§æ•°æ®é›†giraphåªç”¨W1ï¼ŒåŸå› å¦‚ä¸‹ï¼š
## 1ã€ å°æ•°æ®é›†çš„ï¼š
```python?code_reference&code_event_index=1
import pandas as pd

try:
    # Attempt to read the CSV file
    df = pd.read_csv('giraph_random100_fifo.csv', header=5)
except:
    df = pd.read_csv('giraph_random100_fifo.csv', header=4)

# Print basic info
print(f"Total rows: {len(df)}")
print(df.head())
print(df.tail())

```

```text?code_stdout&code_event_index=1
Total rows: 71
             time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
0  15-12 15:14:50              NaN        990164.00      4337844.000          36860.0          2014616       NaN        NaN      NaN        NaN             NaN             NaN             NaN             NaN
1  15-12 15:14:51             0.25             0.50           99.248              0.0                0  989928.0  4338076.0  36860.0  2014620.0        8894.862       10100.843             0.0             0.0
2  15-12 15:14:52             0.50             0.25           99.006              0.0                0  989928.0  4338076.0  36860.0  2014620.0       15301.853       15635.871             0.0             4.0
3  15-12 15:14:53             0.25             0.00           99.257              0.0                0  989928.0  4338076.0  36860.0  2014620.0        4323.291        5211.350             0.0             0.0
4  15-12 15:14:54             0.25             0.50           99.249              0.0                0  989928.0  4338076.0  36860.0  2014620.0         214.997         676.991             0.0             0.0
              time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl       used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
66  15-12 15:15:56             2.75              0.5           96.761              0.0                0  1500972.0  3733332.0  37000.0  2105052.0        1560.178        3775.431             0.0          20.002
67  15-12 15:15:57             0.50              0.0           99.256              0.0                0  1500968.0  3733332.0  37000.0  2105056.0         447.028        1077.068             0.0           0.000
68  15-12 15:15:58             0.50              0.0           98.997              0.0                0  1500968.0  3733332.0  37000.0  2105056.0         172.995         802.977             0.0           4.000
69  15-12 15:15:59             0.50              0.5           98.003              0.0                0  1506472.0  3773580.0  37000.0  2060336.0        4502.152        5536.187             0.0           0.000
70  15-12 15:16:00             1.25              0.5           98.496              0.0                0  1506608.0  3773652.0  37000.0  2060188.0       10324.553       10974.525             0.0           0.000

```

è¿™ä¸ª `random_graph_100` æ•°æ®é›†éå¸¸å°ï¼ˆåªæœ‰ 7KBï¼‰ï¼Œä½†ä»»åŠ¡ä¾ç„¶å¤±è´¥äº†ã€‚ä»ä½ æä¾›çš„ `giraph_random100_fifo.csv` ç›‘æ§æ•°æ®ï¼ˆæ€»å…± 71 ç§’ï¼‰ä»¥åŠä¹‹å‰çš„æ“ä½œæ­¥éª¤åˆ†æï¼Œæœ€å¯èƒ½çš„åŸå› æ˜¯ **ZooKeeper ä¼šè¯è¶…æ—¶** æˆ–è€… **èµ„æºè¯·æ±‚é—®é¢˜**ï¼Œè€Œä¸æ˜¯å†…å­˜ä¸è¶³ï¼ˆå› ä¸ºæ•°æ®å¾ˆå°ï¼‰ã€‚

è¯·æ£€æŸ¥ä»¥ä¸‹ä¸¤ä¸ªæ–¹é¢æ¥ä¿®å¤å®ƒï¼š

#### 1\. æ ¹æœ¬åŸå› åˆ†æ (Root Cause)

  * **æ•°æ®é‡å¤ªå° vs å®¹å™¨æ•°å¤ªå¤š**ï¼šä½ çš„æ•°æ®åªæœ‰ 100 ä¸ªèŠ‚ç‚¹ï¼Œä½†ä½ ç”³è¯·äº† **3 ä¸ª Worker** (`-w 3`)ã€‚
      * Giraph å¯èƒ½è¯•å›¾æŠŠè¿™åŒºåŒº 100 ä¸ªèŠ‚ç‚¹åˆ†ç»™ 3 å°æœºå™¨ï¼Œæ¯å°åˆ†åˆ° 33 ä¸ªç‚¹ã€‚
      * åœ¨å¯åŠ¨ã€è¿æ¥ ZooKeeper å’ŒåŒæ­¥çš„è¿‡ç¨‹ä¸­ï¼ŒæŸäº› Worker å¯èƒ½å› ä¸ºæ•°æ®å¤ªå°‘è·‘å¾—å¤ªå¿«ï¼Œæˆ–è€…å› ä¸ºåè°ƒå¼€é”€è¿‡å¤§å¯¼è‡´åŒæ­¥å¤±è´¥ï¼ˆè¶…æ—¶ï¼‰ã€‚
  * **SplitMasterWorker è®¾ç½®**ï¼šä½ ç”¨äº† `giraph.SplitMasterWorker=true`ï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦ 1 ä¸ª Master + 3 ä¸ª Worker = **4 ä¸ªå®¹å™¨**ã€‚
      * å¦‚æœé›†ç¾¤èµ„æºï¼ˆYARNï¼‰æ­¤æ—¶æ¯”è¾ƒç´§å¼ ï¼ˆFIFO æ¨¡å¼ä¸‹å¯èƒ½æœ‰å…¶ä»–æ®‹ç•™ä»»åŠ¡ï¼‰ï¼Œç”³è¯·ä¸åˆ° 4 ä¸ª Containerï¼Œä»»åŠ¡å°±ä¼šä¸€ç›´å¡ç€ç›´åˆ°è¶…æ—¶å¤±è´¥ã€‚

#### 2\. ä¿®æ­£æ–¹æ¡ˆ (Fix)

å¯¹äºè¿™ä¸ªæå°æ•°æ®é›†ï¼Œä¸éœ€è¦åŠ¨ç”¨å…¨é›†ç¾¤ 3 ä¸ªèŠ‚ç‚¹ï¼Œ**å•èŠ‚ç‚¹è¿è¡Œæœ€ç¨³**ã€‚

**è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼ˆç²¾ç®€ç‰ˆï¼‰é‡è·‘ï¼š**

1.  **å‡å°‘ Worker æ•°é‡**ï¼šæŠŠ `-w 3` æ”¹æˆ `-w 1`ï¼ˆåªç”¨ 1 ä¸ªå¹²æ´»çš„ï¼‰ã€‚
2.  **å–æ¶ˆ Master/Worker åˆ†ç¦»**ï¼šæŠŠ `SplitMasterWorker` æ”¹æˆ `false`ï¼ˆè®© Master åŒæ—¶ä¹Ÿå¹²æ´»ï¼Œçœèµ„æºï¼‰ã€‚
3.  **å†…å­˜ç”¨é»˜è®¤å³å¯**ï¼šå°æ•°æ®ä¸éœ€è¦é‚£å † `-Dmapreduce...` çš„å†…å­˜å‚æ•°ã€‚

**æ–°çš„æäº¤å‘½ä»¤ï¼š**

```bash
# 1. æ¸…ç†è¾“å‡º
hdfs dfs -rm -r /giraph/output_giraph_random100

# 2. æäº¤ä»»åŠ¡ (å•æœºæ¨¡å¼è·‘åˆ†å¸ƒå¼ä»£ç )
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/random_graph_100.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_random100 \
-w 1 \
-ca giraph.SplitMasterWorker=false
```
---
### 2ã€å¤§æ•°æ®é›†çš„ï¼š
### å…ˆå°è¯•äº†æ‰©å¤§å†…å­˜ï¼ˆ0035ï¼‰ï¼Œä½†æ˜¯ä¸è¡Œï¼Œç„¶åç”¨ä»¥ä¸‹çš„ä»£ç åœ¨æ‰©å¤§å†…å­˜åŸºç¡€ä¸ŠæŠŠw3å˜æˆæˆ‘w1å°±å¯ä»¥äº†ï¼š
```python?code_reference&code_event_index=1
import pandas as pd

try:
    # Attempt to read the CSV file
    df = pd.read_csv('giraph_roadNet_fifo_2.csv', header=5)
except:
    df = pd.read_csv('giraph_roadNet_fifo_2.csv', header=4)

# Basic stats
print(f"Total duration: {len(df)} seconds")
print(df.head())
print(df.tail())

# Calculate memory usage growth (used column usually in bytes, convert to GB)
df['used_GB'] = df['used'] / 1024 / 1024 / 1024
print(f"Start Memory: {df['used_GB'].iloc[0]:.2f} GB")
print(f"Peak Memory: {df['used_GB'].max():.2f} GB")
print(f"End Memory: {df['used_GB'].iloc[-1]:.2f} GB")

# Check CPU Wait (IO bottleneck indicator)
print(f"Average CPU Wait: {df['total usage:wai'].mean()}%")
print(f"Peak CPU Wait: {df['total usage:wai'].max()}%")

```

```text?code_stdout&code_event_index=1
Total duration: 498 seconds
             time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
0  15-12 15:22:23              NaN         951292.0      4375220.000          37368.0          2015392       NaN        NaN      NaN        NaN             NaN             NaN             NaN             NaN
1  15-12 15:22:24             0.00              0.0           98.759              0.0                0  951288.0  4375220.0  37368.0  2015396.0       10003.937       11534.081             0.0           0.000
2  15-12 15:22:25             0.25              0.0           99.013              0.0                0  951288.0  4375220.0  37368.0  2015396.0       14148.866       14676.936             0.0          44.006
3  15-12 15:22:26             0.50              0.0           99.239              0.0                0  951280.0  4375220.0  37376.0  2015396.0        2380.734        2776.690             0.0          47.995
4  15-12 15:22:27             0.50              0.0           99.493              0.0                0  951280.0  4375220.0  37376.0  2015396.0         278.981        1158.920             0.0           0.000
               time  total usage:usr  total usage:sys  total usage:idl  total usage:wai  total usage:stl      used       free      buf       cach  net/total:recv  net/total:send  dsk/total:read  dsk/total:writ
493  15-12 15:30:36            0.750             0.25           99.249              0.0                0  965112.0  4313120.0  38148.0  2061564.0       10801.885        5816.938             0.0         175.998
494  15-12 15:30:37            0.250             0.00           99.000              0.0                0  965112.0  4313120.0  38148.0  2061564.0         413.000        4903.000             0.0           8.000
495  15-12 15:30:38            0.000             0.25           98.999              0.0                0  960744.0  4363352.0  38148.0  2016856.0         202.999         634.996             0.0           0.000
496  15-12 15:30:39            0.250             0.75           99.498              0.0                0  960744.0  4363352.0  38148.0  2016856.0         440.993        1325.978             0.0           0.000
497  15-12 15:30:40            0.246             0.00           97.791              0.0                0  960744.0  4363352.0  38148.0  2016856.0        6188.682        6604.480             0.0           3.941
Start Memory: nan GB
Peak Memory: 0.00 GB
End Memory: 0.00 GB
Average CPU Wait: 75.06274899598394%
Peak CPU Wait: 37368.0%

```

ä½ ä¸Šä¼ çš„ `giraph_roadNet_fifo_2.csv` æ–‡ä»¶æ˜¾ç¤ºä»»åŠ¡ä¾ç„¶å¤±è´¥ï¼Œä½†è¿™æ¬¡çš„æƒ…å†µå’Œä¸Šæ¬¡ï¼ˆ48ç§’æŒ‚æ‰ï¼‰å®Œå…¨ä¸åŒã€‚è¿™æ¬¡åšæŒäº† **498ç§’ (8åˆ†å¤šé’Ÿ)** æ‰ç»“æŸï¼

ä»æ•°æ®ä¸­æˆ‘ä»¬å‘ç°äº† **æ–°çš„è‡´å‘½é—®é¢˜**ï¼Œè€Œä¸”è¿™ä¸ªé—®é¢˜éå¸¸éšè”½ï¼š

#### 1\. è‡´å‘½å¼‚å¸¸ï¼šCPU Wait çˆ†è¡¨ (Wait Time: 75%)

  * **æ•°æ®è¯æ®**ï¼š`Average CPU Wait: 75.06%`ã€‚
  * **è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿ**ï¼š
      * æ­£å¸¸è®¡ç®—ä»»åŠ¡ï¼ˆå¦‚ PageRankï¼‰çš„ CPU åº”è¯¥å¿™äºè®¡ç®— (`usr`)ï¼Œè€Œä¸æ˜¯ç­‰å¾… (`wai`)ã€‚
      * **75% çš„æ—¶é—´** CPU éƒ½åœ¨å‚»ç­‰ï¼å®ƒåœ¨ç­‰ä»€ä¹ˆï¼Ÿ**ç­‰ Swapï¼ˆè™šæ‹Ÿå†…å­˜ï¼‰äº¤æ¢**ã€‚
  * **åœºæ™¯é‡ç°**ï¼š
      * ä½ ç»™ Giraph åˆ†é…äº† **4GB å†…å­˜** (`-Dmapreduce.map.memory.mb=4096`)ã€‚
      * ä½†æ˜¯ï¼ä½ çš„æœåŠ¡å™¨èŠ‚ç‚¹ï¼ˆecnu03ï¼‰å¯èƒ½**ç‰©ç†å†…å­˜æœ¬èº«å°±åƒç´§**ã€‚
      * å½“ Java è¿›ç¨‹çœŸçš„å»è¦è¿™ 4GB å†…å­˜æ—¶ï¼Œæ“ä½œç³»ç»Ÿå‘ç°ç‰©ç†å†…å­˜ä¸å¤Ÿäº†ï¼Œäºæ˜¯å¼€å§‹ç–¯ç‹‚åœ°æŠŠå†…å­˜æ•°æ®å†™åˆ°ç¡¬ç›˜çš„ Swap åˆ†åŒºé‡Œï¼Œç„¶åå†è¯»å›æ¥ã€‚
      * è¿™ç§ **"å†…å­˜é¢ ç°¸" (Thrashing)** å¯¼è‡´é€Ÿåº¦æ…¢å¦‚èœ—ç‰›ï¼Œæœ€åå› ä¸ºè¶…æ—¶ï¼ˆTimeoutï¼‰è¢« YARN æ€æ‰ã€‚

#### 2\. å†…å­˜å¹¶æ²¡æœ‰çœŸæ­£æ¶¨ä¸Šå»

  * **æ•°æ®è¯æ®**ï¼š`Peak Memory` åªæœ‰ **0.00 GB**ï¼ˆè¿™é‡Œå¯èƒ½æ˜¯ dstat å•ä½æ¢ç®—é—®é¢˜ï¼Œä½†çœ‹åŸå§‹æ•°æ® `used` åªæœ‰ `960744.0`ï¼Œä¹Ÿå°±æ˜¯ 900MB å·¦å³ï¼‰ã€‚
  * **åˆ†æ**ï¼šè¿™è¯´æ˜ Java è¿›ç¨‹è™½ç„¶ç”³è¯·äº† 4GB çš„ä¸Šé™ï¼Œä½†å®é™…è¿˜æ²¡ç”¨åˆ°é‚£ä¹ˆå¤šï¼Œæœºå™¨å°±å·²ç»å¡æ­»äº†ã€‚æˆ–è€… dstat ç›‘æ§çš„ `used` åŒ…å«äº†è¢«ç¼“å­˜å ç”¨çš„å†…å­˜ï¼Œå¯¼è‡´ä½ çœ‹ä¸åˆ°çœŸå®çš„è¿›ç¨‹å†…å­˜å¢é•¿ã€‚

#### 3\. ç»ˆæè§£å†³æ–¹æ¡ˆï¼šç»™ Giraph "å‡è´Ÿ" (Downsize)

æ—¢ç„¶â€œåŠ å†…å­˜â€ä¼šå¯¼è‡´æœºå™¨å¡æ­»ï¼ˆThrashingï¼‰ï¼Œæˆ‘ä»¬éœ€è¦åå…¶é“è€Œè¡Œä¹‹ï¼š**å‡å°‘å¹¶è¡Œåº¦ï¼Œè®©å•æœºç‹¬äº«èµ„æº**ã€‚

è¿™ä¸ª RoadNet æ•°æ®é›†æœ‰ 200ä¸‡èŠ‚ç‚¹ï¼Œå…¶å® **1 ä¸ª Worker ç»™ 3GB å†…å­˜** æ˜¯å®Œå…¨èƒ½è·‘çš„ï¼Œä¸éœ€è¦ 3 ä¸ª Worker å¹¶è¡Œï¼ˆé‚£æ ·ä¼šç”± 3 ä¸ª JVM æŠ¢èµ„æºï¼‰ã€‚

**è¯·å°è¯•è¿™ä¸ªâ€œå•å…µä½œæˆ˜â€å‘½ä»¤ï¼š**

1.  **å‡å°‘ Worker**ï¼š`-w 1` (åªç”¨ 1 ä¸ª Workerï¼Œé¿å…å¤šè¿›ç¨‹æ‰“æ¶)ã€‚
2.  **å–æ¶ˆåˆ†ç¦»**ï¼š`SplitMasterWorker=false` (Master å’Œ Worker åˆä½“ï¼Œçœæ‰ 1 ä¸ªå®¹å™¨)ã€‚
3.  **å†…å­˜é€‚ä¸­**ï¼šç»™ 3GB å †å†…å­˜ï¼Œé¢„ç•™ä¸€ç‚¹ç»™ç³»ç»Ÿã€‚

**å¤åˆ¶è¿™ä¸ªå‘½ä»¤é‡è·‘ (æœ€åä¸€æ¬¡å°è¯•)ï¼š**

```bash
# 1. æ¸…ç†è¾“å‡ºç›®å½•
hdfs dfs -rm -r /giraph/output_giraph_roadNet_v3

# 2. æäº¤ä»»åŠ¡ (å…³é”®ï¼šä¿ç•™äº† 4GB å†…å­˜å‚æ•°ï¼ŒåŒæ—¶é™åˆ¶ -w 1)
/usr/local/hadoop/bin/hadoop jar /root/giraph/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.7.3-jar-with-dependencies.jar \
org.apache.giraph.GiraphRunner \
-Dmapreduce.framework.name=yarn \
-Dmapreduce.jobtracker.address=ecnu01:8032 \
-Dmapreduce.map.memory.mb=4096 \
-Dmapreduce.map.java.opts=-Xmx3500m \
com.ecnu.pagerank.giraph.PageRankComputation \
-vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
-vip /giraph/input/roadNet-CA_json.txt \
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
-op /giraph/output_giraph_roadNet_v3 \
-w 1 \
-ca giraph.SplitMasterWorker=false \
-ca giraph.zkSessionMsecTimeout=600000
```

---
# å¦‚ä½•ç”¨ `analyze_stragglers.py`å®ŒæˆStraggler (é•¿å°¾ä»»åŠ¡)
è¿™æ˜¯ä¸ºä½ å‡†å¤‡çš„ `analyze_stragglers.py` è„šæœ¬ã€‚

è¿™ä¸ªè„šæœ¬ç»è¿‡äº†ä¸“é—¨ä¼˜åŒ–ï¼Œ**èƒ½å¤Ÿå¤„ç† Hadoop UI ä¸­å¸¸è§çš„å„ç§æ—¶é—´æ ¼å¼**ï¼ˆæ¯”å¦‚ `12sec`, `1min 30sec`, `450ms` ç­‰ï¼‰ï¼Œä½ ç›´æ¥æŠŠç½‘é¡µä¸Šçš„é‚£åˆ—å¤åˆ¶ä¸‹æ¥ç²˜è´´è¿› txt å°±èƒ½è·‘ã€‚

### 1\. è„šæœ¬ä»£ç  (analyze\_stragglers.py)

è¯·åœ¨ä½ çš„ç”µè„‘ï¼ˆæˆ–è€… Master èŠ‚ç‚¹ï¼‰ä¸Šæ–°å»ºä¸€ä¸ªæ–‡ä»¶ï¼Œå‘½åä¸º `analyze_stragglers.py`ï¼Œç„¶åæŠŠä¸‹é¢çš„ä»£ç å®Œå…¨å¤åˆ¶è¿›å»ä¿å­˜ã€‚

```python
import sys
import re
import math

def parse_duration(time_str):
    """
    å°† Hadoop UI çš„æ—¶é—´å­—ç¬¦ä¸² (e.g., "1min 30sec", "450ms", "12sec") 
    ç»Ÿä¸€è½¬æ¢ä¸ºç§’ (float)ã€‚
    """
    # ç§»é™¤å¤šä½™ç©ºæ ¼å¹¶è½¬å°å†™
    s = time_str.strip().lower().replace(",", "")
    
    if not s:
        return None

    total_seconds = 0.0
    
    # 1. å¤„ç†æ¯«ç§’ (ms)
    if 'ms' in s:
        ms_match = re.search(r'(\d+)\s*ms', s)
        if ms_match:
            total_seconds += float(ms_match.group(1)) / 1000.0
        return total_seconds

    # 2. å¤„ç†åˆ†é’Ÿ (min)
    min_match = re.search(r'(\d+)\s*min', s)
    if min_match:
        total_seconds += float(min_match.group(1)) * 60

    # 3. å¤„ç†ç§’ (sec / s)
    sec_match = re.search(r'(\d+)\s*(sec|s)', s)
    if sec_match:
        total_seconds += float(sec_match.group(1))
    
    # 4. å¦‚æœåªæœ‰çº¯æ•°å­—ï¼Œé»˜è®¤å½“ä½œç§’
    if total_seconds == 0:
        try:
            val = float(s)
            return val
        except ValueError:
            return None # æ— æ³•è§£æçš„è„æ•°æ®

    return total_seconds

def analyze_tasks(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ '{file_path}'")
        return

    # è§£ææ•°æ®
    durations = []
    for line in lines:
        val = parse_duration(line)
        if val is not None:
            durations.append(val)

    count = len(durations)
    if count == 0:
        print("æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´æ•°æ®ã€‚")
        return

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    avg_time = sum(durations) / count
    
    # è®¡ç®—æ ‡å‡†å·® (Standard Deviation)
    variance = sum((x - avg_time) ** 2 for x in durations) / count
    std_dev = math.sqrt(variance)

    # å®šä¹‰é•¿å°¾ä»»åŠ¡ (Straggler): è¶…è¿‡å¹³å‡å€¼ 1.5 å€çš„ä»»åŠ¡
    threshold = avg_time * 1.5
    stragglers = [x for x in durations if x > threshold]
    straggler_count = len(stragglers)
    straggler_percentage = (straggler_count / count) * 100

    # æ‰¾åˆ°æœ€æ…¢çš„ä»»åŠ¡
    max_time = max(durations)
    min_time = min(durations)

    # --- è¾“å‡ºæŠ¥å‘Š ---
    print("-" * 40)
    print(f"ä»»åŠ¡è€—æ—¶åˆ†ææŠ¥å‘Š: {file_path}")
    print("-" * 40)
    print(f"æ€»ä»»åŠ¡æ•° (Total Tasks):      {count}")
    print(f"å¹³å‡è€—æ—¶ (Average Time):     {avg_time:.2f} s")
    print(f"æ ‡å‡†å·® (Std Dev):            {std_dev:.2f} s")
    print(f"æœ€å¿«ä»»åŠ¡ (Min Time):         {min_time:.2f} s")
    print(f"æœ€æ…¢ä»»åŠ¡ (Max Time):         {max_time:.2f} s")
    print("-" * 40)
    print(f"é•¿å°¾é˜ˆå€¼ (Avg * 1.5):      > {threshold:.2f} s")
    print(f"é•¿å°¾ä»»åŠ¡æ•° (Stragglers):   {straggler_count}")
    print(f"é•¿å°¾å æ¯” (Percentage):     {straggler_percentage:.2f}%")
    print("-" * 40)
    
    # ç®€çŸ­ç»“è®ºå»ºè®®
    print("\n[æŠ¥å‘Š]:")
    if straggler_percentage > 5:
        print(f"  > æ£€æµ‹åˆ°æ˜æ˜¾çš„è´Ÿè½½ä¸å‡è¡¡ï¼Œé•¿å°¾ä»»åŠ¡å æ¯” {straggler_percentage:.1f}%ã€‚")
        print(f"  > æœ€æ…¢ä»»åŠ¡è€—æ—¶æ˜¯æœ€å¿«ä»»åŠ¡çš„ {max_time/min_time:.1f} å€ï¼Œè¯´æ˜å­˜åœ¨ã€æœ¨æ¡¶æ•ˆåº”ã€ã€‚")
    else:
        print(f"  > è´Ÿè½½ç›¸å¯¹å‡è¡¡ï¼Œé•¿å°¾ä»»åŠ¡è¾ƒå°‘ã€‚")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python analyze_stragglers.py <ä½ çš„æ•°æ®æ–‡ä»¶.txt>")
    else:
        analyze_tasks(sys.argv[1])
```

-----

### 2\. ä½¿ç”¨æ–¹æ³•å®æˆ˜

å‡è®¾ä½ ç°åœ¨è·‘å®Œäº† **Medium æ•°æ®é›† (Stanford) çš„ MapReduce ä½œä¸š**ï¼š

**ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡æ•°æ®æ–‡ä»¶**

1.  å» Hadoop UI -\> Job -\> Map Tasksã€‚
```
åœ¨ MapReduce PageRank è¿™ç§è¿­ä»£ç®—æ³•ä¸­ï¼Œé€‰æ‹©å“ªä¸€è½® Job çš„æ•°æ®è‡³å…³é‡è¦ï¼Œé€‰é”™äº†ä¼šè®©ä½ çš„ç»“è®ºå®Œå…¨ç«™ä¸ä½è„šã€‚
**ç»“è®ºï¼šè¯·é€‰æ‹©ä¸­é—´è½®æ¬¡ï¼ˆä¾‹å¦‚ç¬¬ 5 è½®æˆ–ç¬¬ 6 è½®ï¼‰çš„ Jobã€‚**

### 1. ä¸ºä»€ä¹ˆé€‰â€œä¸­é—´è½®æ¬¡â€ï¼Ÿ

* **é¿å¼€å†·å¯åŠ¨ï¼ˆJob 1-2ï¼‰**ï¼šå‰ä¸¤è½®è¿­ä»£æ—¶ï¼ŒJVM åˆšåˆšå¯åŠ¨ï¼ˆWarm-upï¼‰ï¼Œç¼“å­˜ï¼ˆCacheï¼‰è¿˜æ²¡çƒ­ï¼Œè€Œä¸”å¯èƒ½æœ‰é¢å¤–çš„æ•°æ®åŠ è½½å¼€é”€ã€‚è¿™æ—¶å€™çš„æ•°æ®æ³¢åŠ¨å¾ˆå¤§ï¼Œä¸èƒ½ä»£è¡¨ç®—æ³•çš„çœŸå®æ°´å¹³ã€‚
* **é¿å¼€æ”¶å°¾ï¼ˆJob 9-10ï¼‰**ï¼šæœ€åå‡ è½®è™½ç„¶ç¨³å®šï¼Œä½†æœ‰æ—¶ä¼šå› ä¸ºæ”¶æ•›æ£€æŸ¥ï¼ˆConvergence Checkï¼‰æˆ–å…¶ä»–æ¸…ç†å·¥ä½œå¯¼è‡´æ•°æ®ç•¥æœ‰åå·®ã€‚
* **ä¸­é—´æœ€ç¨³ï¼ˆJob 5-6ï¼‰**ï¼šè¿™æ˜¯**â€œç¨³æ€ï¼ˆStable Stateï¼‰â€**ã€‚æ­¤æ—¶ JVM å·²ç»çƒ­èº«å®Œæ¯•ï¼Œæ•°æ®æµç¨³å®šï¼Œæœ€èƒ½åæ˜ è°ƒåº¦ç­–ç•¥ï¼ˆFIFO vs Fairï¼‰å’Œæ•°æ®å€¾æ–œï¼ˆStragglerï¼‰çš„çœŸå®å½±å“ã€‚

### 2. åªæœ‰â€œç¬¬ 5 è½®â€å°±å¤Ÿäº†å—ï¼Ÿï¼ˆè¿›é˜¶æŠ€å·§ï¼‰

è™½ç„¶é€‰ç¬¬ 5 è½®æ²¡é—®é¢˜ï¼Œä½†ä¸ºäº†é˜²æ­¢è¿™ä¸€è½®æ°å¥½â€œè¿æ°”çˆ†æ£šâ€æˆ–è€…â€œè¿æ°”æå·®â€ï¼Œæœ€ç§‘å­¦çš„åšæ³•æ˜¯ï¼š

1.  **å¿«é€Ÿæ‰«è§†**ï¼šåœ¨ Hadoop UI çš„ Job åˆ—è¡¨ä¸­ï¼Œçœ‹ä¸€çœ¼ç¬¬ 4ã€5ã€6 è½®çš„ `Elapsed Time`ï¼ˆæ€»è€—æ—¶ï¼‰ã€‚
2.  **æ’é™¤å¼‚å¸¸**ï¼šå¦‚æœç¬¬ 5 è½®ç”¨äº† 30sï¼Œè€Œç¬¬ 4ã€6 è½®éƒ½ç”¨äº† 50sï¼Œé‚£ç¬¬ 5 è½®å¯èƒ½æ˜¯å¼‚å¸¸å€¼ï¼Œ**é€‰é‚£ä¸ªè€—æ—¶æœ€æ¥è¿‘å¹³å‡æ°´å¹³çš„**ã€‚
3.  **æœ€ç»ˆå†³å®š**ï¼šé€šå¸¸ç›´æ¥é€‰ **Job 6** æ˜¯æœ€ä¿é™©çš„ã€‚

### 3. é€‰æ‹© Map Tasks è¿˜æ˜¯ Reduce Tasksï¼Ÿï¼ˆå…³é”®ï¼ï¼‰

ä½ åœ¨æé—®ä¸­è¯´â€œé€‰ä¸­ Elapsed é‚£ä¸€æ•´åˆ—... å» Job -> Map Tasksâ€ï¼Œ**è¿™é‡Œéœ€è¦åœä¸€ä¸‹ç¡®è®¤ç“¶é¢ˆåœ¨å“ªé‡Œ**ã€‚

PageRank åœ¨ MapReduce ä¸­çš„é•¿å°¾ï¼ˆStragglerï¼‰å¯èƒ½å‡ºç°åœ¨ Map é˜¶æ®µï¼Œä¹Ÿå¯èƒ½å‡ºç°åœ¨ Reduce é˜¶æ®µï¼Œå–å†³äºä½ çš„å®ç°å’Œå›¾ç»“æ„ï¼š

* **å¦‚æœ Map é˜¶æ®µå¾ˆæ…¢ï¼ˆè¯»æ•°æ®æ…¢ï¼‰**ï¼šæ¯”å¦‚æŸä¸ª Split ç‰¹åˆ«å¤§ã€‚ -> **é€‰ Map Tasks**ã€‚
* **å¦‚æœ Reduce é˜¶æ®µå¾ˆæ…¢ï¼ˆShuffle æ…¢/è®¡ç®—æ…¢ï¼‰**ï¼šæ¯”å¦‚æŸä¸ªâ€œè¶…çº§èŠ‚ç‚¹ï¼ˆSuper Nodeï¼‰â€æœ‰å‡ ç™¾ä¸‡æ¡è¾¹ï¼Œå¯¼è‡´æŸä¸ª Reducer æ¥æ”¶äº† 90% çš„æ•°æ®ï¼ˆæ•°æ®å€¾æ–œï¼‰ã€‚ -> **é€‰ Reduce Tasks**ã€‚

**åˆ¤æ–­æ–¹æ³•**ï¼š
çœ‹ Job Overview é¡µé¢ï¼š
* å¦‚æœ `Average Map Time` = 10sï¼Œ`Average Reduce Time` = 50s â€”â€” **è¯·å»å¤åˆ¶ Reduce Tasks çš„æ—¶é—´ï¼**ï¼ˆå› ä¸ºç“¶é¢ˆåœ¨ Reduceï¼ŒStraggler è‚¯å®šè—åœ¨é‚£ï¼‰ã€‚
* å¦‚æœ Map å å¤§å¤´ï¼Œå°±å¤åˆ¶ Mapã€‚

### 4. æ•°æ®æ ¼å¼é¢„è­¦ï¼ˆå¿…çœ‹ï¼ï¼‰

ä½ æåˆ°çš„å¤åˆ¶å†…å®¹åŒ…å« `1min 2sec` å’Œ `12sec`ã€‚
**âš ï¸ æ³¨æ„ï¼š** ä½ çš„ `analyze_stragglers.py` è„šæœ¬å¯èƒ½å¾ˆç®€é™‹ï¼Œä¸ä¸€å®šèƒ½è¯»æ‡‚ "min" å’Œ "sec" è¿™ç§æ··åˆå•ä½ã€‚

* **å¦‚æœè„šæœ¬æŠ¥é”™**ï¼šä½ å¯èƒ½éœ€è¦æ‰‹åŠ¨æŠŠ `1min 2sec` æ”¹æˆ `62`ï¼ˆç§’ï¼‰ï¼ŒæŠŠ `12sec` æ”¹æˆ `12`ã€‚
* **Excel å°æŠ€å·§**ï¼šå…ˆæŠŠæ•°æ®ç²˜è´´åˆ° Excelï¼Œç”¨å…¬å¼æŠŠå®ƒä»¬ç»Ÿä¸€è½¬æ¢æˆâ€œç§’â€ä¸ºå•ä½çš„çº¯æ•°å­—ï¼Œç„¶åå†å¤åˆ¶åˆ° `mr_tasks.txt` é‡Œã€‚è¿™æ ·è„šæœ¬è¿è¡Œç»å¯¹ä¸ä¼šå‡ºé—®é¢˜ã€‚

---

### ğŸ“ ç»„å‘˜ C çš„æ“ä½œä¿®æ­£æ€»ç»“

1.  æ‰“å¼€ Hadoop UIï¼Œæ‰¾åˆ° **PageRank Iteration 6 (æˆ–è€…ç¬¬ 6 ä¸ª Job)**ã€‚
2.  çœ‹ä¸€çœ¼ Overviewï¼Œç¡®è®¤æ˜¯ **Map æ…¢** è¿˜æ˜¯ **Reduce æ…¢**ã€‚
3.  ç‚¹è¿›æ…¢çš„é‚£ä¸ªé˜¶æ®µï¼ˆTasks åˆ—è¡¨ï¼‰ã€‚
4.  å¤åˆ¶ **Elapsed Time** åˆ—ã€‚
5.  **æ¸…æ´—æ•°æ®**ï¼šç¡®ä¿è½¬æˆçº¯æ•°å­—ï¼ˆç§’ï¼‰ï¼Œæˆ–è€…ç¡®è®¤ä½ çš„è„šæœ¬èƒ½å¤„ç† "min/sec" æ ¼å¼ã€‚
6.  è¿è¡Œè„šæœ¬ï¼š`python analyze_stragglers.py mr_tasks.txt`ã€‚

è¿™æ ·åšå‡ºæ¥çš„ Straggler åˆ†æï¼Œè€å¸ˆç»å¯¹æŒ‘ä¸å‡ºæ¯›ç—…ï¼
```
2.  é¼ æ ‡é€‰ä¸­ `Elapsed` é‚£ä¸€æ•´åˆ—ï¼ˆæ¯”å¦‚æœ‰ 50 è¡Œï¼‰ï¼Œå¤åˆ¶ã€‚
3.  åœ¨æœ¬åœ°æ–°å»ºæ–‡ä»¶ `mr_tasks.txt`ï¼Œç²˜è´´è¿›å»ã€‚å†…å®¹å¤§æ¦‚é•¿è¿™æ ·ï¼š
    ```text
    12sec
    14sec
    1min 2sec
    13sec
    ...
    ```
4.  ä¿å­˜ã€‚


**ç¬¬äºŒæ­¥ï¼šè¿è¡Œè„šæœ¬**
åœ¨ç»ˆç«¯ï¼ˆTerminalï¼‰è¾“å…¥ï¼š

```bash
python analyze_stragglers.py mr_tasks.txt
```

**ç¬¬ä¸‰æ­¥ï¼šçœ‹ç»“æœå¡«è¡¨**
è„šæœ¬ä¼šè¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼Œç›´æ¥å¡«è¿›ä½ çš„ç›‘æµ‹è¡¨æ ¼ï¼š

```text
----------------------------------------
ğŸ“Š ä»»åŠ¡è€—æ—¶åˆ†ææŠ¥å‘Š: mr_tasks.txt
----------------------------------------
æ€»ä»»åŠ¡æ•° (Total Tasks):      100
å¹³å‡è€—æ—¶ (Average Time):     15.50 s
æ ‡å‡†å·® (Std Dev):            8.20 s   <-- å¡«å…¥è¡¨æ ¼
æœ€å¿«ä»»åŠ¡ (Min Time):         12.00 s
æœ€æ…¢ä»»åŠ¡ (Max Time):         62.00 s  <-- å¡«å…¥è¡¨æ ¼
----------------------------------------
ğŸ¢ é•¿å°¾é˜ˆå€¼ (Avg * 1.5):      > 23.25 s
ğŸ¢ é•¿å°¾ä»»åŠ¡æ•° (Stragglers):   4        <-- å¡«å…¥è¡¨æ ¼
ğŸ¢ é•¿å°¾å æ¯” (Percentage):     4.00%
----------------------------------------
```
---
## ç¬¬å››é˜¶æ®µï¼šFIFO ä¸“å±â€œé«˜åˆ†â€å®éªŒ (å¹¶å‘é˜»å¡æµ‹è¯•)

**ç›®æ ‡**ï¼šè¯æ˜ FIFO è°ƒåº¦å™¨å­˜åœ¨â€œæ’å¤´é˜»å¡â€ç°è±¡ï¼ˆå¤§ä½œä¸šæœªå®Œæˆå‰ï¼Œå°ä½œä¸šæ— æ³•å¼€å§‹ï¼‰ã€‚

1.  **å‡†å¤‡ä¸¤ä¸ªç»ˆç«¯çª—å£**ï¼Œå‡è¿æ¥åˆ° Master (`ecnu01`)ã€‚

2.  **çª—å£ 1ï¼šæäº¤å¤§ä»»åŠ¡ (Giraph)**

      * ç›´æ¥è¿è¡Œç¬¬ä¸‰é˜¶æ®µçš„ Giraph æäº¤å‘½ä»¤ã€‚

3.  **çª—å£ 2ï¼šç«‹å³æäº¤å°ä»»åŠ¡ (MapReduce)**

      * åœ¨ Giraph å¼€å§‹è¿è¡Œåï¼ˆçº¦ 5-10ç§’ï¼‰ï¼Œç«‹å³æäº¤ä¸€ä¸ªå°æ•°æ®é›†ä»»åŠ¡ï¼š

    <!-- end list -->

    ```bash
    # ç¡®ä¿å°æ•°æ®åœ¨ formatted_graph ç›®å½•ï¼Œæˆ–è€…ç›´æ¥ç”¨ random_graph_100
    # è¿™é‡Œå‡è®¾ Driver é»˜è®¤è¯»çš„æ˜¯ formatted_graph (é‡Œè¾¹æ˜¯å¤§æ–‡ä»¶)ï¼Œä½ å¯ä»¥ä¸´æ—¶æŒ‡å®šä¸€ä¸ªå°æ–‡ä»¶
    # æˆ–è€…ç›´æ¥æäº¤è¿™ä¸ªå‘½ä»¤ï¼Œåæ­£å®ƒä¼šå¡ä½ï¼š
    /usr/local/hadoop/bin/hadoop jar PageRank-ECNU-1.0-SNAPSHOT.jar com.ecnu.pagerank.mr.PageRankDriver
    ```

    *(æ³¨ï¼šå¦‚æœæ²¡æœ‰å°æ•°æ®ï¼Œç›´æ¥å†æ¬¡æäº¤ MapReduce å¤§ä»»åŠ¡ä¹Ÿå¯ä»¥ï¼Œåªè¦èƒ½çœ‹åˆ°æ’é˜Ÿå°±è¡Œ)*

4.  **ğŸ“¸ å…³é”®æˆªå›¾æ—¶åˆ»**

      * åˆ·æ–° YARN Web ç•Œé¢ (`http://106.15.248.68:8088`)ã€‚
      * **ç°è±¡**ï¼šä½ ä¼šçœ‹åˆ° Giraph ä»»åŠ¡çŠ¶æ€ä¸º `RUNNING`ï¼Œè€Œåˆšæ‰æäº¤çš„ MapReduce ä»»åŠ¡çŠ¶æ€ä¸º **`ACCEPTED`**ï¼ˆæ³¨æ„ï¼šä¸æ˜¯ RUNNINGï¼Œä¸”è¿›åº¦æ¡ä¸åŠ¨ï¼‰ã€‚
      * **æˆªå›¾è¦æ±‚**ï¼šæˆªå–åŒ…å«è¿™ä¸¤ä¸ªä»»åŠ¡çŠ¶æ€çš„åˆ—è¡¨ï¼Œè¯æ˜ MapReduce è¢« Giraph â€œå µâ€ä½äº†ã€‚

5.  **å®éªŒç»“æŸ**

      * ç­‰å¾… Giraph è·‘å®Œï¼Œä½ ä¼šå‘ç° MapReduce ç¬é—´å˜ä¸º `RUNNING`ã€‚

-----